{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 问题\n",
    "\n",
    "- [x] 长文本截断时尽量保留首尾，效果不怎么样。。。\n",
    "- [ ] 在上面的基础上考虑双向lstm\n",
    "- [x] 采用将类别添加到text头部的方式\n",
    "- [ ] summaryWriter版本问题\n",
    "- [x] 损失函数应为交叉损失，而不是BCELoss，这是用于多标签的\n",
    "- [x] iter可以被设置设备，所以训练时不用再to(device)，可以用batch.text.device查看是否正确。对于模型，next(model.parameters()).device\n",
    "- [x] ~~field有问题~~。预先数字化，再设置use_vocab=False\n",
    "- [ ] test相关代码还没写\n",
    "- [x] ~~生成iter时会将df的头部也当作数据传进处理中，所以会导致列名'type'也传进了处理函数中~~。data.TabularDataset(skip_header=True)\n",
    "- [ ] text生成有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#!pip show torch torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle  #变色\n",
    "% matplotlib inline\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy import data\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda import amp\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#from transformers import TrainingArguments,Trainer\n",
    "#from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "\n",
    "import os\n",
    "import re\n",
    "import gc  #垃圾回收\n",
    "\n",
    "from tqdm import tqdm  #进度条 for data in tqdm(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputData size:  torch.Size([64, 10])\n",
      "encode out size:  torch.Size([64, 10, 128])\n",
      "encode h size:  torch.Size([1, 64, 128])\n",
      ",encode c size:  torch.Size([1, 64, 128])\n",
      "decode out shape:  torch.Size([64, 10, 10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义模型参数\n",
    "vocab_size = 10000  # 词汇表大小\n",
    "max_sequence_length = 10  # 句子长度\n",
    "embedding_dim = 32\n",
    "hidden_units = 128\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# 定义编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        encoder_outputs, (encoder_state_h, encoder_state_c) = self.lstm(x)\n",
    "        return encoder_outputs, encoder_state_h, encoder_state_c\n",
    "\n",
    "\n",
    "# 定义解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "        self.attention = nn.Linear(hidden_units, hidden_units)\n",
    "        self.out = nn.Linear(hidden_units, vocab_size)\n",
    "\n",
    "    def forward(self, x, encoder_outputs, encoder_state_h):\n",
    "        x = self.embedding(x)\n",
    "        decoder_outputs, _ = self.lstm(x, (encoder_state_h, encoder_state_h))\n",
    "\n",
    "        # 注意力机制\n",
    "        attn_scores = torch.matmul(decoder_outputs, encoder_outputs.permute(0, 2, 1))\n",
    "        attn_weights = torch.nn.functional.softmax(attn_scores, dim=-1)\n",
    "        context = torch.matmul(attn_weights, encoder_outputs)\n",
    "        decoder_outputs = decoder_outputs + context\n",
    "\n",
    "        decoder_outputs = self.out(decoder_outputs)\n",
    "\n",
    "        return decoder_outputs\n",
    "\n",
    "\n",
    "# 定义Seq2Seq模型\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, encoder_inputs, decoder_inputs):\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = self.encoder(encoder_inputs)\n",
    "        decoder_outputs = self.decoder(decoder_inputs, encoder_outputs, encoder_state_h)\n",
    "        return decoder_outputs\n",
    "\n",
    "\n",
    "# 创建编码器和解码器\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "\n",
    "# 创建Seq2Seq模型\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def a():\n",
    "    inputData = torch.randint(0, 1000, (batch_size, max_sequence_length))\n",
    "    print(\"inputData size: \", inputData.shape)\n",
    "\n",
    "    encodeRes = encoder(inputData)\n",
    "    print(\"encode out size: \", encodeRes[0].shape)\n",
    "    print(\"encode h size: \", encodeRes[1].shape)\n",
    "    print(\",encode c size: \", encodeRes[2].shape)\n",
    "\n",
    "    inputDataD = torch.randint(0, 1000, (batch_size, max_sequence_length))\n",
    "    decodeRes = decoder(inputDataD, encodeRes[0], encodeRes[1])\n",
    "\n",
    "    print(\"decode out shape: \", decodeRes.shape)\n",
    "\n",
    "\n",
    "a()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"E:/DATA/feedback-prize-effectiveness/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   discourse_id      essay_id  \\\n",
      "0  0013cc385424  007ACE74B050   \n",
      "1  9704a709b505  007ACE74B050   \n",
      "2  c22adee811b6  007ACE74B050   \n",
      "3  a10d361e54e4  007ACE74B050   \n",
      "4  db3e453ec4e2  007ACE74B050   \n",
      "\n",
      "                                      discourse_text discourse_type  \\\n",
      "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
      "1  On my perspective, I think that the face is a ...       Position   \n",
      "2  I think that the face is a natural landform be...          Claim   \n",
      "3  If life was on Mars, we would know by now. The...       Evidence   \n",
      "4  People thought that the face was formed by ali...   Counterclaim   \n",
      "\n",
      "  discourse_effectiveness  \n",
      "0                Adequate  \n",
      "1                Adequate  \n",
      "2                Adequate  \n",
      "3                Adequate  \n",
      "4                Adequate  \n",
      "Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. \n",
      "36765\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(data_dir + \"train.csv\")\n",
    "print(df1.head())\n",
    "print(df1.iloc[0]['discourse_text'])\n",
    "print(len(df1))\n",
    "#essay_id   txt文件名\n",
    "#discourse_id   段落的id，应该没用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "discourse_id               0\nessay_id                   0\ndiscourse_text             0\ndiscourse_type             0\ndiscourse_effectiveness    0\ndtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concluding Statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Counterclaim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rebuttal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         discourse_type\n",
       "0                 Claim\n",
       "1  Concluding Statement\n",
       "2          Counterclaim\n",
       "3              Evidence\n",
       "4                  Lead\n",
       "5              Position\n",
       "6              Rebuttal"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['discourse_type']].apply(np.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ineffective</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  discourse_effectiveness\n",
       "0                Adequate\n",
       "1               Effective\n",
       "2             Ineffective"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['discourse_effectiveness']].apply(np.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   discourse_id      essay_id  \\\n",
      "0  a261b6e14276  D72CB1C11673   \n",
      "1  5a88900e7dc1  D72CB1C11673   \n",
      "2  9790d835736b  D72CB1C11673   \n",
      "3  75ce6d68b67b  D72CB1C11673   \n",
      "4  93578d946723  D72CB1C11673   \n",
      "\n",
      "                                      discourse_text discourse_type  \n",
      "0  Making choices in life can be very difficult. ...           Lead  \n",
      "1  Seeking multiple opinions can help a person ma...       Position  \n",
      "2                     it can decrease stress levels           Claim  \n",
      "3             a great chance to learn something new           Claim  \n",
      "4               can be very helpful and beneficial.           Claim  \n",
      "Making choices in life can be very difficult. People often ask for advice when they can not decide on one thing. It's always good to ask others for their advice when making a choice. When you have multiple opinions you have the ability to make the best choice for yourself. \n",
      "10\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(data_dir + \"test.csv\")\n",
    "print(df2.head())\n",
    "print(df2.iloc[0]['discourse_text'])\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_id      0\n",
       "essay_id          0\n",
       "discourse_text    0\n",
       "discourse_type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear: Principal\n",
      "\n",
      "I am arguing against the policy change because even though there are some children out there that really needs help with their academic work, that does not mean that only because they have a c average that would not let them enjoy their sports or other activities unless they've a B average.\n",
      "\n",
      "Sometimes teachers or even principal needs to consider that we should give the help that any student should have. Also this may consider student self as steam. Meaning student would start to feel sad nervous, and not wanting to go to school because of the reason they have a low averages and they can not participate in other activities or sports. The fact that there are children that would want to enjoy many good things the school is actually giving it to them.\n",
      "\n",
      "We would want to make changes as, \"like to be a better person for a better tomorrow\" This supports the idea of having have many good thoughts and incasing your work as much as possible. In some situation like arguing we should make a vote to see if kids would want to have a school policy of change and having to participate in fun activities but they first need to have at least a B average. Some reasons I would be against the school policy change is because you would feel ashame and then many bad things could happen meaning, you would be angry etc. In additionally , I think that student should have sports because it helps them with their health, and problems that they would have personal. I am against this policy change.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Student.\n",
      "-------\n",
      "Dear Florida senator,\n",
      "\n",
      "I would like disuss why changing up the way we voyte today is not as bad f an idea as it sounds. Changing to elections by a popular vote sounds like its in the peoples hands instead of juts casting out votes on the slate electors. Aren't we voting for our president. innstead of countting onn the electoral votes to hep out or, go against out favor, it'd be much more easier to just let the people vote.\n",
      "\n",
      "The elctoral votes are utterly useless or unimportant,though. If there is ever happens to be a tie between the two candidates the electoral votes can help break it. It'd be less of a hassle to have the florida residents vote,directly, on someone besides the president. Less worring about if theyre going to win or not. Now when you start to think about it the electoral college is just unfair an pretty outdated,if you ask me. Change doesn't sound that bad. All im trying to achive by writting this, is to gain actual control over who we're all voting for.\n",
      "\n",
      "It's also not just what's completely wrong with the electoral college but how does it help in the first place? When you start analizing it, it really doens't help much. How much actual help can the lectora coellge make, in my defense not much. Why? Simple, its just 20-30 more votes and not many states have that much Hawaii has uop to 4 electoral votes, not much. Voters should be alowed to directly vote for who they want to be president and not rely on the lectoral college.    \n"
     ]
    }
   ],
   "source": [
    "with open(data_dir + \"/train/000E6DE9E817.txt\") as f:\n",
    "    print(f.read())\n",
    "print(\"-------\")\n",
    "with open(data_dir + \"/train/00B144412785.txt\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 1 44.75033319733442 28.0\n"
     ]
    }
   ],
   "source": [
    "df1['wordcount'] = df1['discourse_text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    ")\n",
    "print(\n",
    "    np.max(df1['wordcount']), np.min(df1['wordcount']),\n",
    "    np.average(df1['wordcount']), np.median(df1['wordcount'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(221)\n",
    "plt.hist(x=list(df1['wordcount']), bins=80)\n",
    "plt.subplot(222)\n",
    "plt.hist(x=list(df1[df1['wordcount'] <= 200]['wordcount']), bins=40)\n",
    "plt.subplot(223)\n",
    "plt.bar(x=[0, 1], height=[len(df1[df1['wordcount'] <= 50]), len(df1[df1['wordcount'] > 50])])\n",
    "plt.subplot(224)\n",
    "plt.bar(x=[0, 1], height=[len(df1[df1['wordcount'] <= 128]), len(df1[df1['wordcount'] > 128])])\n",
    "plt.show()\n",
    "\n",
    "#考虑到这是论述文，所以开头结尾比较重要，数据处理时需要考虑到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cc921c5cfda4</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>stress.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>1ab1030c639a</td>\n",
       "      <td>0A5B8761B187</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Position</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>210f8f088aa4</td>\n",
       "      <td>1B4E66B0BE0A</td>\n",
       "      <td>pollution.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>e18b753a740a</td>\n",
       "      <td>1DC6485ABFF6</td>\n",
       "      <td>interest,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>91b5849cdbed</td>\n",
       "      <td>1DC6485ABFF6</td>\n",
       "      <td>funds/workers.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>6826ef3d5b63</td>\n",
       "      <td>34C979F3ABAA</td>\n",
       "      <td>promoting</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>461645ee618c</td>\n",
       "      <td>34C979F3ABAA</td>\n",
       "      <td>protection</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>439210ca27fb</td>\n",
       "      <td>34C979F3ABAA</td>\n",
       "      <td>bills</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>aa83e041a0aa</td>\n",
       "      <td>3E866ECC376A</td>\n",
       "      <td>enthusiastic,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Effective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4539</th>\n",
       "      <td>8ced2bb31129</td>\n",
       "      <td>50F1D8786126</td>\n",
       "      <td>emotions</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      discourse_id      essay_id   discourse_text discourse_type  \\\n",
       "11    cc921c5cfda4  00944C693682         stress.           Claim   \n",
       "452   1ab1030c639a  0A5B8761B187        Disagree        Position   \n",
       "1397  210f8f088aa4  1B4E66B0BE0A      pollution.           Claim   \n",
       "1571  e18b753a740a  1DC6485ABFF6       interest,           Claim   \n",
       "1572  91b5849cdbed  1DC6485ABFF6  funds/workers.           Claim   \n",
       "2907  6826ef3d5b63  34C979F3ABAA       promoting           Claim   \n",
       "2908  461645ee618c  34C979F3ABAA      protection           Claim   \n",
       "2909  439210ca27fb  34C979F3ABAA           bills           Claim   \n",
       "3456  aa83e041a0aa  3E866ECC376A   enthusiastic,           Claim   \n",
       "4539  8ced2bb31129  50F1D8786126        emotions           Claim   \n",
       "\n",
       "     discourse_effectiveness  wordcount  \n",
       "11                  Adequate          1  \n",
       "452              Ineffective          1  \n",
       "1397                Adequate          1  \n",
       "1571             Ineffective          1  \n",
       "1572             Ineffective          1  \n",
       "2907             Ineffective          1  \n",
       "2908                Adequate          1  \n",
       "2909                Adequate          1  \n",
       "3456               Effective          1  \n",
       "4539                Adequate          1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['wordcount'] == 1].head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "## 数据基本处理\n",
    "\n",
    "1. 一般语言处理中对全部数据只会取常用的n个词，在此之外的词是不认识的，即先有一本字典\n",
    "\n",
    "2. 用one-hot编码时，每个词都表示为长n的向量，其中只有一个值是1，其余全是0。\n",
    "   比如字典的第i（0开始）个单词其one-hot编码中1值的下标是i\n",
    "\n",
    "## embedding\n",
    "\n",
    "1. one_hot编码稀疏，所以考虑用稠密向量表示词，比如只用长为m（m<n）的向量表示n个单词，其中单词间关系可以体现在向量间关系中，比如$\\vec{男}+\\vec{国王}=\\vec{皇帝}$\n",
    "\n",
    "2. 可由embedding层实现这个，embedding记录了一个(n,m)的矩阵，每行都是一个单词的稠密向量，作用是one-hot编码的向量按照其1值的下标i访问这个矩阵第i行，取出这行向量作为新输入\n",
    "   \n",
    "3. 具体使用看下面代码说明\n",
    "   \n",
    "4. embedding可自行训练出，也可预加载预训练参数。使用预训练参数时，冻结此层\n",
    "\n",
    "## 初步结果\n",
    "\n",
    "将batch_size\\*len_sentences\\*n变为batch_size\\*len_sentences\\*m\n",
    "\n",
    "## rnn具体流程\n",
    "\n",
    "1. 首先初始化hadden_input为全0\n",
    "   \n",
    "2. 对每个词，其经过线性层后都会和当前的hadden_input结合(cat或add)并进行一步激活（tanh）运算，所得的输出作为新的hadden_input作为下一个词的初始hadden_input\n",
    "   \n",
    "3. cat（最后一维）的话，需要截断，或者另外卷积一次获得新hadden_input\n",
    "   \n",
    "4. pytorch的rnn为x[i]通过一liner，hidden通过一liner，两个结果相加经Tanh激活，结果作为新hidden，具体见下面代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before embedding:torch.Size([4, 20])\n",
      "after embedding:torch.Size([4, 20, 8])\n",
      "-------------\n",
      "rnn input:torch.Size([20, 4, 8])\n",
      "rnn out:torch.Size([20, 4, 128])\n",
      "rnn outh:torch.Size([4, 128])\n",
      "-----------\n",
      "finally shape:torch.Size([4, 2])\n",
      "tensor([[0.5867, 0.4133],\n",
      "        [0.3925, 0.6075],\n",
      "        [0.4375, 0.5625],\n",
      "        [0.4605, 0.5395]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# rnn内部细节\n",
    "batch_size = 4\n",
    "sentence_len = 20  #一句话20个词\n",
    "words_num = 100  #字典记录了100个词\n",
    "vector_len = 8  #字典的每个词向量长8\n",
    "X = torch.randint(0, words_num, [batch_size, sentence_len])  #注意输入不为one-hot，只是每个词的字典序号，比如[3,2,10]表示一句话。int\n",
    "y = torch.as_tensor([[0., 1], [0, 1], [1, 0], [1, 0]])\n",
    "#print(X)\n",
    "\n",
    "hidden_layer_num = 1  #多少个hidden用于循环，即多少个循环部分\n",
    "\n",
    "\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = 128\n",
    "        self.embedding_layer = nn.Embedding(words_num, vector_len, padding_idx=0)  #100*8,padding_idx为输入长度不够时填充的字典词序号\n",
    "\n",
    "        #一个循环节\n",
    "        self.hidden_layer_x = nn.Linear(vector_len, self.hidden_size)  #rnn关键部分\n",
    "        self.hidden_layer_h = nn.Linear(self.hidden_size, self.hidden_size)  #给h用\n",
    "\n",
    "        #分类器\n",
    "        self.out_layer = nn.Linear(self.hidden_size, 2)\n",
    "        self.activation_layer = nn.Softmax(dim=-1)  #dim=0表示a[i][j][k]按i方向的几个数一起算\n",
    "\n",
    "    def __init_hidden(self):\n",
    "        return torch.zeros([hidden_layer_num, batch_size, self.hidden_size])\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hidden = self.__init_hidden()\n",
    "\n",
    "        print(f\"before embedding:{x.shape}\")  #[4, 20]\n",
    "        x = self.embedding_layer(x)\n",
    "        print(f\"after embedding:{x.shape}\")  #[4, 20, 8]\n",
    "        print(\"-------------\")\n",
    "\n",
    "        out = torch.zeros([sentence_len, batch_size, self.hidden_size])\n",
    "\n",
    "        #rnn部分\n",
    "        # 为了更好计算，将数据x变形为为len_sencentces*batch_size*words_num\n",
    "        # 即x[0]为各句子首单词\n",
    "        x = x.transpose(0, 1)\n",
    "        print(f\"rnn input:{x.shape}\")  #[20, 4, 128]\n",
    "        for i in range(x.shape[0]):\n",
    "            a1 = self.hidden_layer_x(x[i])\n",
    "            a2 = self.hidden_layer_h(self.hidden[0])\n",
    "\n",
    "            out[i] = self.hidden[0] = nn.Tanh()(a1 + a2)\n",
    "        print(f\"rnn out:{out.shape}\")\n",
    "        print(f\"rnn outh:{self.hidden[0].shape}\")\n",
    "        print(\"-----------\")\n",
    "\n",
    "        #分类器\n",
    "        o = self.hidden[0]  #即out[x.shape[0]-1]\n",
    "        o = self.out_layer(o)\n",
    "        o = self.activation_layer(o)\n",
    "        print(f\"finally shape:{o.shape}\")  #[4, 2]\n",
    "        print(o)\n",
    "\n",
    "        return o\n",
    "\n",
    "\n",
    "rnn = MyRNN()\n",
    "out = rnn(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch的rnn\n",
    "\n",
    "- 首先就是输入是batch_size\\*len_sencentces\\*words_num\n",
    "  \n",
    "    所以Embedding算是预处理部分，如果需要训练则？？？？？？？？\n",
    "    \n",
    "- 主要公式\n",
    "\n",
    "    $$h_t = \\tanh(x_t W_{ih} + b_{ih} + h_{t-1}W_{hh} + b_{hh})$$\n",
    "\n",
    "    - t\n",
    "\n",
    "      t为时刻，实质是到第t个字\n",
    "\n",
    "    - i\n",
    "\n",
    "      词向量的初始长度\n",
    "\n",
    "    - h\n",
    "\n",
    "      隐藏层大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 8])\n",
      "torch.Size([2, 5, 32]) torch.Size([1, 2, 32])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "sentence_len = 5\n",
    "words_num = 10\n",
    "words_len = 8\n",
    "\n",
    "X = torch.randint(0, words_num, [batch_size, sentence_len])\n",
    "\n",
    "X = nn.Embedding(words_num, words_len)(X)\n",
    "#X = X.transpose(0,1) #batch_size放在第二维，则batch_first设置为False\n",
    "print(X.shape)\n",
    "\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "H = torch.zeros([num_layers, batch_size, hidden_size])  #可以不设置，则默认为0，这是单向rnn\n",
    "#HH = torch.zeros([num_layers*2,batch_size,hidden_size]) #双向rnn，需要RNN中设置bidirectional=True\n",
    "\n",
    "rnn = nn.RNN(\n",
    "    input_size=words_len,\n",
    "\n",
    "    #hidden_size，num_layers 都是对网络的设置，与输入数据无关，设置相对自由\n",
    "    hidden_size=hidden_size,  # hidden层大小\n",
    "    num_layers=num_layers,  # n个rnn层\n",
    "\n",
    "    batch_first=True,  #True则输入输出的batch在第一维，否则在第二维（参照上面MyRNN在hidden前的变形）\n",
    "\n",
    "    bidirectional=False,  #是否双向rnn\n",
    ")\n",
    "\n",
    "out, outh = rnn(X, H)  #out为h的集合\n",
    "print(out.shape, outh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([32, 8]) <class 'torch.nn.parameter.Parameter'>\n",
      "weight_hh_l0 torch.Size([32, 32]) <class 'torch.nn.parameter.Parameter'>\n",
      "bias_ih_l0 torch.Size([32]) <class 'torch.nn.parameter.Parameter'>\n",
      "bias_hh_l0 torch.Size([32]) <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for i in rnn.named_parameters():\n",
    "    print(i[0], i[1].shape, type(i[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 4])\n",
      "pytorch部分\n",
      "torch.Size([2, 5, 8]) torch.Size([1, 2, 8])\n",
      "tensor([-0.7137,  0.5926, -0.6244,  0.6198, -0.1706, -0.5207, -0.0612,  0.4735],\n",
      "       grad_fn=<SliceBackward>) \n",
      " tensor([-0.8456,  0.2111,  0.1764,  0.7712, -0.0146, -0.7987, -0.6467,  0.7652],\n",
      "       grad_fn=<SliceBackward>)\n",
      "-------------------\n",
      "MyCNN部分\n",
      "torch.Size([2, 5, 8]) torch.Size([1, 2, 8])\n",
      "tensor([-0.7137,  0.5926, -0.6244,  0.6198, -0.1706, -0.5207, -0.0612,  0.4735],\n",
      "       grad_fn=<SliceBackward>) \n",
      " tensor([-0.8456,  0.2111,  0.1764,  0.7712, -0.0146, -0.7987, -0.6467,  0.7652],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1024)\n",
    "\n",
    "batch_size = 2\n",
    "sentence_len = 5\n",
    "words_num = 10\n",
    "vector_len = 4\n",
    "\n",
    "hidden_size = 8\n",
    "num_layers = 1\n",
    "\n",
    "X = torch.randint(0, words_num, (batch_size, sentence_len))\n",
    "em = nn.Embedding(words_num, vector_len)\n",
    "X = em(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('pytorch部分')\n",
    "rnn = nn.RNN(\n",
    "    input_size=vector_len,\n",
    "\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "\n",
    "    batch_first=True,\n",
    ")\n",
    "out, outh = rnn(X)\n",
    "print(out.shape, outh.shape)\n",
    "print(outh[0, 0, :], '\\n', out[0, 0, :])\n",
    "print('-------------------')\n",
    "\n",
    "print('MyCNN部分')\n",
    "\n",
    "\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layer_x = nn.Linear(vector_len, hidden_size)  #rnn关键部分\n",
    "        self.hidden_layer_h = nn.Linear(hidden_size, hidden_size)  #h用\n",
    "\n",
    "        #注意这里无条件复制w、b，所以最好先判断两者形状相等再赋值\n",
    "        params = list(rnn.parameters())\n",
    "        # assert self.hidden_layer_x.weight.shape == params[0].shape and\n",
    "        #        self.hidden_layer_h.weight.shape == params[1].shape and\n",
    "        #        self.hidden_layer_x.bias.shape == params[2].shape and\n",
    "        #        self.hidden_layer_h.bias.shape == params[3].shape,\n",
    "        #     print(\"shape error\")\n",
    "\n",
    "        self.hidden_layer_x.weight = params[0]\n",
    "        self.hidden_layer_h.weight = params[1]\n",
    "        self.hidden_layer_x.bias = params[2]\n",
    "        self.hidden_layer_h.bias = params[3]\n",
    "\n",
    "    def __init_hidden(self):\n",
    "        return torch.zeros([num_layers, batch_size, hidden_size])\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hidden = self.__init_hidden()\n",
    "\n",
    "        out = torch.zeros([sentence_len, batch_size, hidden_size])\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "        for i in range(x.shape[0]):\n",
    "            a1 = self.hidden_layer_x(x[i])\n",
    "            a2 = self.hidden_layer_h(self.hidden[0])\n",
    "            self.hidden[0] = nn.Tanh()(a1 + a2)\n",
    "\n",
    "            out[i] = self.hidden[0]\n",
    "\n",
    "        return out.transpose(0, 1)\n",
    "\n",
    "\n",
    "myrnn = MyRNN()\n",
    "out = myrnn(X)\n",
    "print(out.shape, myrnn.hidden.shape)\n",
    "print(myrnn.hidden[0, 0, :], '\\n', out[0, 0, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "## 基本理解\n",
    "- rnn因为激活层是Tanh，显然，当前信息几乎不会对很远的计算产生影响，即只能短期记忆\n",
    "- lstm中引入可以选择“记忆”和“当前”的信息在当前输出的占比 \n",
    "## 具体介绍 \n",
    "- 输入是H（类似于rnn的hidden作用），C（当前记忆）\n",
    "- 一个单元分为记忆门，遗忘门，rnn门，输出门，其相当于四次rnn变换，只不过功能和激活函数不同\n",
    "   - 记忆门i，Sigmoid激活，即当前rnn输出需要记哪些信息到记忆C中\n",
    "   - 遗忘门f，Sigmoid激活，即原先记忆需要遗忘哪些信息\n",
    "   - rnn门g，Tanh激活，就是rnn\n",
    "   - 输出门o，Sigmoid激活，控制新记忆哪些作为新H\n",
    "- 公式如下\n",
    "$$\n",
    "    \\begin{array}{ll} \\\\\n",
    "        i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
    "        f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
    "        g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n",
    "        o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
    "        c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
    "        h_t = o_t \\odot \\tanh(c_t) \\\\\n",
    "    \\end{array}\n",
    "$$\n",
    "## pytorch内部细节\n",
    "- 将四个变换按维度一放在一起，同时计算四个门激活前的输出，输出顺序如上顺序，见如下代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 4])\n",
      "pytorch部分\n",
      "torch.Size([2, 5, 16]) torch.Size([1, 2, 16]) torch.Size([1, 2, 16])\n",
      "tensor([ 0.0842,  0.0372, -0.1389,  0.0300, -0.1425,  0.0223,  0.0017,  0.3239,\n",
      "        -0.0413, -0.0924, -0.1835,  0.0621,  0.0484, -0.0894,  0.2133,  0.0063],\n",
      "       grad_fn=<SliceBackward>)\n",
      "-------------------\n",
      "MyLSTM部分\n",
      "torch.Size([2, 5, 16]) torch.Size([1, 2, 16]) torch.Size([1, 2, 16])\n",
      "tensor([ 0.0842,  0.0372, -0.1389,  0.0300, -0.1425,  0.0223,  0.0017,  0.3239,\n",
      "        -0.0413, -0.0924, -0.1835,  0.0621,  0.0484, -0.0894,  0.2133,  0.0063],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1024)\n",
    "\n",
    "batch_size = 2\n",
    "sentence_len = 5\n",
    "words_num = 10\n",
    "words_len = 4\n",
    "\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "\n",
    "X = torch.randint(0, words_num, (batch_size, sentence_len))\n",
    "em = nn.Embedding(words_num, words_len)\n",
    "X = em(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('pytorch部分')\n",
    "lstm = nn.LSTM(\n",
    "    input_size=words_len,\n",
    "\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "\n",
    "    batch_first=True,\n",
    ")\n",
    "H = torch.zeros([num_layers, batch_size, hidden_size])\n",
    "C = torch.zeros([num_layers, batch_size, hidden_size])\n",
    "out, (outh, outc) = lstm(X, (H, C))  #H、C默认为0\n",
    "print(out.shape, outh.shape, outc.shape)\n",
    "print(out[0, 0, :])\n",
    "print('-------------------')\n",
    "\n",
    "print('MyLSTM部分')\n",
    "\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layer_x = nn.Linear(words_len, hidden_size * 4)  #4*32，即同时输出4组\n",
    "        self.hidden_layer_h = nn.Linear(hidden_size, hidden_size * 4)  #8*32\n",
    "\n",
    "        params = list(lstm.parameters())\n",
    "        # assert self.hidden_layer_x.weight.shape == params[0].shape and\n",
    "        #        self.hidden_layer_h.weight.shape == params[1].shape and\n",
    "        #        self.hidden_layer_x.bias.shape == params[2].shape and\n",
    "        #        self.hidden_layer_h.bias.shape == params[3].shape,\n",
    "        #     print(\"shape error\")\n",
    "\n",
    "        self.hidden_layer_x.weight = params[0]\n",
    "        self.hidden_layer_h.weight = params[1]\n",
    "        self.hidden_layer_x.bias = params[2]\n",
    "        self.hidden_layer_h.bias = params[3]\n",
    "\n",
    "    def __init_H_C(self):\n",
    "        return torch.zeros([num_layers, batch_size, hidden_size]),\n",
    "               torch.zeros([num_layers, batch_size, hidden_size])\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.H, self.C = self.__init_H_C()\n",
    "        #H是输出\n",
    "        #C是记忆\n",
    "\n",
    "        out = torch.zeros([sentence_len, batch_size, hidden_size])\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "        for i in torch.arange(x.shape[0]):\n",
    "            a1 = self.hidden_layer_x(x[i])\n",
    "            a2 = self.hidden_layer_h(self.H[0])\n",
    "            a = a1 + a2\n",
    "\n",
    "            remember_gate = nn.Sigmoid()(a[:, :hidden_size * 1])  #记住下面op什么信息\n",
    "            forget_gate = nn.Sigmoid()(a[:, hidden_size * 1:hidden_size * 2])  #C遗忘什么信息\n",
    "            op = nn.Tanh()(a[:, hidden_size * 2:hidden_size * 3])\n",
    "            output_gate = nn.Sigmoid()(a[:, hidden_size * 3:])  #最终输出\n",
    "\n",
    "            self.C[0] = self.C[0] * forget_gate + remember_gate * op  #新的记忆\n",
    "            self.H[0] = nn.Tanh()(self.C) * output_gate  #生成新的输出\n",
    "\n",
    "            out[i] = self.H[0]\n",
    "\n",
    "        return out.transpose(0, 1)\n",
    "\n",
    "\n",
    "mylstm = MyLSTM()\n",
    "out = mylstm(X)\n",
    "print(out.shape, mylstm.C.shape, mylstm.H.shape)\n",
    "print(out[0, 0, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化\n",
    "- 遗忘门=1-记忆门，减少运算次数\n",
    "- 。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# attention\n",
    "\n",
    "语句在文章内，所以以文章为一个数据，可在每段上放上一个特殊标记分隔段落\n",
    "\n",
    "用attention机制学习"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 676\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36m<cell line: 101>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;66;03m#print(enc_out.shape, enc_h.shape, enc_c.shape) # torch.Size([64, 10, 128]) torch.Size([1, 10, 128]) torch.Size([1, 10, 128])\u001B[39;00m\n\u001B[0;32m     97\u001B[0m     model(x,y)\n\u001B[1;32m--> 101\u001B[0m \u001B[43ma\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py:28\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m():\n\u001B[1;32m---> 28\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36ma\u001B[1;34m()\u001B[0m\n\u001B[0;32m     94\u001B[0m enc_out, (enc_h, enc_c) \u001B[38;5;241m=\u001B[39m enc(x)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;66;03m#print(enc_out.shape, enc_h.shape, enc_c.shape) # torch.Size([64, 10, 128]) torch.Size([1, 10, 128]) torch.Size([1, 10, 128])\u001B[39;00m\n\u001B[1;32m---> 97\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1047\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1052\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1053\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mSeq2Seq.forward\u001B[1;34m(self, src, trg, teacher_forcing_ratio)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m trg[\u001B[38;5;241m0\u001B[39m, :]\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, trg_len):\n\u001B[1;32m---> 73\u001B[0m     output, hidden, cell \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m     outputs[t] \u001B[38;5;241m=\u001B[39m output\n\u001B[0;32m     75\u001B[0m     teacher_force \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m \u001B[38;5;241m<\u001B[39m teacher_forcing_ratio\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1047\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1052\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1053\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mDecoder.forward\u001B[1;34m(self, input, hidden, cell, encoder_outputs)\u001B[0m\n\u001B[0;32m     52\u001B[0m weighted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbmm(a, encoder_outputs)\n\u001B[0;32m     53\u001B[0m weighted \u001B[38;5;241m=\u001B[39m weighted\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 54\u001B[0m rnn_input \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mcat((embedded, weighted), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     55\u001B[0m output, (hidden, cell) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrnn(rnn_input, (hidden, cell))\n\u001B[0;32m     56\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc_out(output\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m))\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mDecoder.forward\u001B[1;34m(self, input, hidden, cell, encoder_outputs)\u001B[0m\n\u001B[0;32m     52\u001B[0m weighted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbmm(a, encoder_outputs)\n\u001B[0;32m     53\u001B[0m weighted \u001B[38;5;241m=\u001B[39m weighted\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 54\u001B[0m rnn_input \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mcat((embedded, weighted), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     55\u001B[0m output, (hidden, cell) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrnn(rnn_input, (hidden, cell))\n\u001B[0;32m     56\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc_out(output\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1180\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:621\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:930\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:921\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:318\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义模型超参数\n",
    "batch_size = 64\n",
    "encoder_seq_length = 10\n",
    "decoder_seq_length = 10\n",
    "embedding_dim = 32\n",
    "hidden_units = 128\n",
    "\n",
    "# 构建编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, bidirectional=False)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return outputs, (hidden, cell)\n",
    "\n",
    "# 构建注意力机制\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(enc_hidden_dim + dec_hidden_dim, dec_hidden_dim)\n",
    "        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size, _, _ = encoder_outputs.shape\n",
    "        hidden = hidden.repeat(batch_size, 1, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return torch.softmax(attention, dim=1)\n",
    "\n",
    "# 构建解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim + hidden_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.attention = attention\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.embedding(input)\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# 定义Seq2Seq模型\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = 0.1 < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs\n",
    "\n",
    "# 创建模型实例\n",
    "INPUT_DIM = 10000  # 假设输入词汇表大小为10000\n",
    "OUTPUT_DIM = 10000  # 假设输出词汇表大小为10000\n",
    "\n",
    "enc = Encoder(INPUT_DIM, embedding_dim, hidden_units)\n",
    "attn = Attention(hidden_units, hidden_units)\n",
    "dec = Decoder(OUTPUT_DIM, embedding_dim, hidden_units, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec)\n",
    "\n",
    "@torch.no_grad()\n",
    "def a():\n",
    "    x = torch.randint(0, 10000, (64, 10))\n",
    "    y = torch.randint(0, 10000, (64, 10))\n",
    "    enc_out, (enc_h, enc_c) = enc(x)\n",
    "    #print(enc_out.shape, enc_h.shape, enc_c.shape) # torch.Size([64, 10, 128]) torch.Size([1, 10, 128]) torch.Size([1, 10, 128])\n",
    "\n",
    "    model(x,y)\n",
    "\n",
    "\n",
    "\n",
    "a()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train'] ['sample_submission.csv', 'test.csv', 'train.csv', '来源.txt']\n"
     ]
    }
   ],
   "source": [
    "#阅览数据\n",
    "data_dir = \"E:/DATA/feedback-prize-effectiveness/\"\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    print(dirs, files)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  \n",
       "0                Adequate  \n",
       "1                Adequate  \n",
       "2                Adequate  \n",
       "3                Adequate  \n",
       "4                Adequate  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_type             [Lead, Position, Claim, Evidence, Counterclaim...\n",
       "discourse_effectiveness                   [Adequate, Ineffective, Effective]\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['discourse_type', 'discourse_effectiveness']].apply(pd.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4191\n",
      "4191\n"
     ]
    }
   ],
   "source": [
    "print(len(pd.unique(train_df['essay_id'])))\n",
    "for _, _, files in os.walk(os.path.join(data_dir, \"train\")):\n",
    "    print(len(files))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>a great chance to learn something new</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>can be very helpful and beneficial.</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  a261b6e14276  D72CB1C11673   \n",
       "1  5a88900e7dc1  D72CB1C11673   \n",
       "2  9790d835736b  D72CB1C11673   \n",
       "3  75ce6d68b67b  D72CB1C11673   \n",
       "4  93578d946723  D72CB1C11673   \n",
       "\n",
       "                                      discourse_text discourse_type  \n",
       "0  Making choices in life can be very difficult. ...           Lead  \n",
       "1  Seeking multiple opinions can help a person ma...       Position  \n",
       "2                     it can decrease stress levels           Claim  \n",
       "3             a great chance to learn something new           Claim  \n",
       "4               can be very helpful and beneficial.           Claim  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\n",
    "test_df.head()\n",
    "\n",
    "#可知文本类型已知，所以考虑如何将文本类型作为输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [Lead]\n",
       "1                [Position]\n",
       "2                   [Claim]\n",
       "3                   [Claim]\n",
       "4                   [Claim]\n",
       "5                [Evidence]\n",
       "6                [Evidence]\n",
       "7                   [Claim]\n",
       "8                [Evidence]\n",
       "9    [Concluding Statement]\n",
       "Name: discourse_type, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['discourse_type'].apply(pd.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(pd.unique(test_df['essay_id'])))\n",
    "for _, _, files in os.walk(os.path.join(data_dir, \"test\")):\n",
    "    print(len(files))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>ef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  type  ef\n",
       "0  007ACE74B050  Hi, i'm Isaac, i'm going to be writing about h...     1   1\n",
       "1  007ACE74B050  On my perspective, I think that the face is a ...     2   1\n",
       "2  007ACE74B050  I think that the face is a natural landform be...     3   1\n",
       "3  007ACE74B050  If life was on Mars, we would know by now. The...     4   1\n",
       "4  007ACE74B050  People thought that the face was formed by ali...     5   1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#列的处理\n",
    "data_dir = \"E:/DATA/feedback-prize-effectiveness/\"\n",
    "train_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "\n",
    "needed_col = ['essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness']\n",
    "train_df = train_df[needed_col]\n",
    "train_df.columns = ['id', 'text', 'type', 'ef']\n",
    "\n",
    "#typ = {'Lead':1,'Position':2, 'Claim':3, 'Evidence':4, 'Counterclaim':5, 'Rebuttal':6, 'Concluding Statement':7}\n",
    "#eff = {'Adequate':1, 'Ineffective':2, 'Effective':3}\n",
    "#train_df['type'] = train_df['type'].apply(lambda x:typ[x])\n",
    "#train_df['ef'] = train_df['ef'].apply(lambda x:eff[x])\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "train_df.to_csv(os.path.join(data_dir, \"proc_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_dir, \"proc_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext' has no attribute 'legacy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32me:\\project\\python\\feedback-prize-effectiveness\\exp.ipynb Cell 61\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001B[0m \u001B[39m#词处理\u001B[39;00m\n\u001B[1;32m----> <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#Y114sZmlsZQ%3D%3D?line=1'>2</a>\u001B[0m torchtext\u001B[39m.\u001B[39;49mlegacy\u001B[39m.\u001B[39mdata\n\u001B[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#Y114sZmlsZQ%3D%3D?line=2'>3</a>\u001B[0m text_field \u001B[39m=\u001B[39m torchtext\u001B[39m.\u001B[39mdata\u001B[39m.\u001B[39mField(sequential\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m, tokenize\u001B[39m=\u001B[39m\u001B[39m'\u001B[39m\u001B[39mspacy\u001B[39m\u001B[39m'\u001B[39m,lower\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m,batch_first\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m) \u001B[39m#会自行处理停用词和符号\u001B[39;00m\n\u001B[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#Y114sZmlsZQ%3D%3D?line=3'>4</a>\u001B[0m label_field \u001B[39m=\u001B[39m torchtext\u001B[39m.\u001B[39mdata\u001B[39m.\u001B[39mField(sequential\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m,use_vocab\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m)\u001B[39m#是单独的类别，而不是文本，原数据可以是数字\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torchtext' has no attribute 'legacy'"
     ]
    }
   ],
   "source": [
    "#词处理\n",
    "text_field = torchtext.data.Field(sequential=True, tokenize='spacy', lower=True, batch_first=True)  #会自行处理停用词和符号\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)  #是单独的类别，而不是文本，原数据可以是数字\n",
    "\n",
    "fields = [('id', None), ('text', text_field), ('type', label_field), ('ef', label_field)]\n",
    "train_dataset = torchtext.data.TabularDataset(os.path.join(data_dir, \"proc_train.csv\"), 'csv', fields)\n",
    "\n",
    "text_field.build_vocab(train_dataset, vector='glove.6B.100d')\n",
    "label_field.build_vocab(train_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "data_dir = \"E:/DATA/feedback-prize-effectiveness/\"\n",
    "\n",
    "assist_dir = \"./assist/\"\n",
    "if (not os.path.exists(assist_dir)):\n",
    "    os.mkdir(assist_dir)\n",
    "models_dir = \"./models_dir/\"\n",
    "if (not os.path.exists(models_dir)):\n",
    "    os.mkdir(models_dir)\n",
    "exp_name = \"exp1\"\n",
    "exp_dir = os.path.join(models_dir, exp_name)\n",
    "if (not os.path.exists(exp_dir)):\n",
    "    os.mkdir(exp_dir)\n",
    "\n",
    "word_count = 60  #不能让大部分数据空值太多\n",
    "max_word_count = 100  #超过这个值考虑取首尾\n",
    "word_vector_dir = \"E:/DATA/glove.6B/\"\n",
    "\n",
    "stop_words_file = \"E:/DATA/english_stop_words.txt\"\n",
    "\n",
    "train_batch_size = 64\n",
    "valid_batch_size = 128\n",
    "test_batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "seed = 101\n",
    "\n",
    "\n",
    "def set_seed():\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed()\n",
    "\n",
    "exp_name = \"exp1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 未优化版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只运行一次，产生处理过的csv\n",
    "\n",
    "#列重命名\n",
    "train_df1 = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "needed_col = ['essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness']\n",
    "train_df1 = train_df1[needed_col]\n",
    "train_df1.columns = ['id', 'text', 'type', 'ef']\n",
    "\n",
    "#type加到text首\n",
    "train_df1['text'] = train_df1[['text', 'type']].apply(\n",
    "    lambda x: x[1] + \".\" + x[0] if x[1] == \"Concluding Statement\" else \"Conclusion.\" + x[0], axis=1)\n",
    "\n",
    "#type数字化\n",
    "typ = {'Claim': 0, \"Concluding Statement\": 1, \"Counterclaim\": 2, \"Evidence\": 3, \"Lead\": 4, \"Position\": 5, \"Rebuttal\": 6}\n",
    "train_df1['type'] = train_df1['type'].apply(lambda x: typ[x])\n",
    "#ef数字化\n",
    "eff = {'Adequate': 0, 'Ineffective': 1, 'Effective': 2}\n",
    "train_df1['ef'] = train_df1['ef'].apply(lambda x: eff[x])\n",
    "\n",
    "#统计单词个数供划分用\n",
    "train_df1['word_count'] = train_df1['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    ")\n",
    "\n",
    "#分训练集验证集\n",
    "train_df1['fold'] = [-1] * len(train_df1)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for i, (train_i, valid_i) in enumerate(skf.split(train_df1, train_df1['type'])):\n",
    "    train_df1.loc[valid_i, 'fold'] = i + 1\n",
    "train_df = train_df1[train_df1['fold'] != 1]\n",
    "train_df = train_df.drop(labels=['fold'], axis=1)\n",
    "valid_df = train_df1[train_df1['fold'] == 1]\n",
    "valid_df = valid_df.drop(labels=['fold'], axis=1)\n",
    "\n",
    "#保存\n",
    "train_df.to_csv(os.path.join(assist_dir, \"train.csv\"), index=None)\n",
    "valid_df.to_csv(os.path.join(assist_dir, \"valid.csv\"), index=None)\n",
    "\n",
    "#测试集，也需要对text进行处理，同时获取word_count\n",
    "test_df = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\n",
    "needed_col = ['essay_id', 'discourse_text', 'discourse_type']\n",
    "test_df = test_df[needed_col]\n",
    "test_df.columns = ['id', 'text', 'type']\n",
    "\n",
    "test_df['text'] = test_df[['text', 'type']].apply(\n",
    "    lambda x: x[1] + \".\" + x[0] if x[1] == \"Concluding Statement\" else \"Conclusion.\" + x[0], axis=1)\n",
    "#type数字化\n",
    "typ = {'Claim': 0, \"Concluding Statement\": 1, \"Counterclaim\": 2, \"Evidence\": 3, \"Lead\": 4, \"Position\": 5, \"Rebuttal\": 6}\n",
    "test_df['type'] = test_df['type'].apply(lambda x: typ[x])\n",
    "\n",
    "#为了下面生成train、valid、test的代码可以写到一起，对test也设计ef列\n",
    "test_df['ef'] = [0] * len(test_df)\n",
    "\n",
    "test_df['word_count'] = test_df['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    ")\n",
    "\n",
    "test_df.to_csv(os.path.join(assist_dir, \"test.csv\"), index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(321)\n",
    "plt.hist(x=list(train_df1['word_count']), bins=80)\n",
    "\n",
    "plt.subplot(322)\n",
    "plt.hist(x=list(train_df1[train_df1['word_count'] <= 200]['word_count']), bins=20)\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.bar(x=[0, 1], height=[len(train_df1[train_df1['word_count'] <= word_count]),\n",
    "                          len(train_df1[train_df1['word_count'] > word_count])])\n",
    "\n",
    "plt.subplot(324)\n",
    "plt.bar(x=[0, 1], height=[len(train_df1[train_df1['word_count'] <= max_word_count]),\n",
    "                          len(train_df1[train_df1['word_count'] > max_word_count])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         word_count\ncount  36765.000000\nmean      45.841480\nstd       46.842673\nmin        2.000000\n25%       17.000000\n50%       29.000000\n75%       58.000000\nmax      837.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36765.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>45.841480</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>46.842673</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>17.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>29.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>58.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>837.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1[['word_count']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化版\n",
    "\n",
    "数据好像没什么变化？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只有训练集进行太长截断取首尾\n",
    "\n",
    "#列重命名\n",
    "train_df1 = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "needed_col = ['essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness']\n",
    "train_df1 = train_df1[needed_col]\n",
    "train_df1.columns = ['id', 'text', 'type', 'ef']\n",
    "\n",
    "#type加到text首\n",
    "train_df1['text'] = train_df1[['text', 'type']].apply(\n",
    "    lambda x: x[1] + \".\" + x[0] if x[1] == \"Concluding Statement\" else \"Conclusion.\" + x[0], axis=1)\n",
    "\n",
    "#type数字化\n",
    "typ = {'Claim': 0, \"Concluding Statement\": 1, \"Counterclaim\": 2, \"Evidence\": 3, \"Lead\": 4, \"Position\": 5, \"Rebuttal\": 6}\n",
    "train_df1['type'] = train_df1['type'].apply(lambda x: typ[x])\n",
    "#ef数字化\n",
    "eff = {'Adequate': 0, 'Ineffective': 1, 'Effective': 2}\n",
    "train_df1['ef'] = train_df1['ef'].apply(lambda x: eff[x])\n",
    "\n",
    "#验证集的text保存原样\n",
    "train_df1['word_count'] = train_df1['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    ")\n",
    "\n",
    "#划分\n",
    "train_df1['fold'] = [-1] * len(train_df1)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for i, (train_i, valid_i) in enumerate(skf.split(train_df1, train_df1['type'])):\n",
    "    train_df1.loc[valid_i, 'fold'] = i + 1\n",
    "train_df = train_df1[train_df1['fold'] != 1]\n",
    "train_df = train_df.drop(labels=['fold'], axis=1)\n",
    "valid_df = train_df1[train_df1['fold'] == 1]\n",
    "valid_df = valid_df.drop(labels=['fold'], axis=1)\n",
    "\n",
    "valid_df.to_csv(os.path.join(assist_dir, \"valid1.csv\"), index=None)\n",
    "\n",
    "\n",
    "#对训练集再单独处理\n",
    "def f(x):\n",
    "    #句子太长优先取首尾\n",
    "    text = x['text']\n",
    "    sp_word = r\"[\\n|\\s|,|?|!|.]\"\n",
    "    sp_sentence = r\"[\\n|?|!|.]\"  #不以,划分\n",
    "\n",
    "    L = len(list(filter(None, re.split(sp_word, text))))\n",
    "    if L > max_word_count:\n",
    "        sentences = list(filter(None, re.split(sp_sentence, text)))\n",
    "\n",
    "        if len(sentences) == 1:\n",
    "            return text\n",
    "\n",
    "        res = sentences[0] + \".\" + sentences[1] + \".\" + sentences[-1] + \".\"\n",
    "\n",
    "        i = 2\n",
    "        while len(list(filter(None, re.split(sp_word, res)))) < word_count:\n",
    "            if i == len(sentences) - 1:\n",
    "                break\n",
    "            res += sentences[i] + \".\"\n",
    "\n",
    "            i += 1\n",
    "        return res\n",
    "\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n",
    "train_df['text'] = train_df[['text']].apply(f, axis=1)\n",
    "train_df['word_count'] = train_df['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    ")\n",
    "train_df.to_csv(os.path.join(assist_dir, \"train1.csv\"), index=None)\n",
    "\n",
    "#测试集也不用截断\n",
    "test_df = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\n",
    "needed_col = ['essay_id', 'discourse_text', 'discourse_type']\n",
    "test_df = test_df[needed_col]\n",
    "test_df.columns = ['id', 'text', 'type']\n",
    "\n",
    "test_df['text'] = test_df[['text', 'type']].apply(\n",
    "    lambda x: x[1] + \".\" + x[0] if x[1] == \"Concluding Statement\" else \"Conclusion.\" + x[0], axis=1)\n",
    "\n",
    "#type数字化\n",
    "typ = {'Claim': 0, \"Concluding Statement\": 1, \"Counterclaim\": 2, \"Evidence\": 3, \"Lead\": 4, \"Position\": 5, \"Rebuttal\": 6}\n",
    "test_df['type'] = test_df['type'].apply(lambda x: typ[x])\n",
    "\n",
    "#为了下面生成train、valid、test的代码可以写到一起，对test也设计ef列\n",
    "test_df['ef'] = [0] * len(test_df)\n",
    "\n",
    "test_df['word_count'] = test_df['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    ")\n",
    "\n",
    "test_df.to_csv(os.path.join(assist_dir, \"test1.csv\"), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         word_count\ncount  36765.000000\nmean      45.841480\nstd       46.842673\nmin        2.000000\n25%       17.000000\n50%       29.000000\n75%       58.000000\nmax      837.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36765.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>45.841480</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>46.842673</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>17.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>29.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>58.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>837.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1[['word_count']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(321)\n",
    "plt.hist(x=list(train_df1['word_count']), bins=80)\n",
    "\n",
    "plt.subplot(322)\n",
    "plt.hist(x=list(train_df1[train_df1['word_count'] <= 200]['word_count']), bins=20)\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.bar(x=[0, 1], height=[len(train_df1[train_df1['word_count'] <= word_count]),\n",
    "                          len(train_df1[train_df1['word_count'] > word_count])])\n",
    "\n",
    "plt.subplot(324)\n",
    "plt.bar(x=[0, 1], height=[len(train_df1[train_df1['word_count'] <= max_word_count]),\n",
    "                          len(train_df1[train_df1['word_count'] > max_word_count])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460 58 1\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(assist_dir, \"train.csv\"))\n",
    "valid_df = pd.read_csv(os.path.join(assist_dir, \"valid.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(assist_dir, \"test.csv\"))\n",
    "\n",
    "# 词处理\n",
    "with open(stop_words_file, 'r') as f:\n",
    "    stop_words = [i.split(\"\\n\")[0] for i in f.readlines()]\n",
    "text_field = data.Field(\n",
    "    sequential=True,\n",
    "    tokenize='spacy',\n",
    "    tokenizer_language=\"en_core_web_sm\",\n",
    "    lower=True,\n",
    "    batch_first=True,\n",
    "    fix_length=word_count,\n",
    "    stop_words=stop_words\n",
    ")\n",
    "label_field = data.Field(sequential=False, use_vocab=False)  #已经是数字，所以use_vocab=False\n",
    "\n",
    "#就是这里，需要它们的fields都为这个\n",
    "fields = [('id', None), ('text', text_field), ('type', label_field), ('ef', label_field), ('wordcount', label_field)]\n",
    "\n",
    "train_ds, valid_ds, test_ds = data.TabularDataset.splits(\n",
    "    path=assist_dir, format='csv',\n",
    "    train='train.csv', validation='valid.csv', test='test.csv',\n",
    "    fields=fields,\n",
    "    skip_header=True\n",
    ")\n",
    "\n",
    "text_field.build_vocab(\n",
    "    train_ds, valid_ds, test_ds,\n",
    "    vectors='glove.6B.50d',\n",
    "    vectors_cache=word_vector_dir\n",
    ")\n",
    "label_field.build_vocab(train_ds, valid_ds, test_ds)\n",
    "\n",
    "'''\n",
    "for w,i in text_field.vocab.stoi.items():#词和相应index\n",
    "    print(w,i)\n",
    "print(text_field.vocab.vectors.shape)#[29278, 100]\n",
    "'''\n",
    "\n",
    "train_iter, valid_iter, test_iter = torchtext.legacy.data.BucketIterator.splits(  #长度相似的会放同一批\n",
    "    (train_ds, valid_ds, test_ds),\n",
    "    batch_sizes=(train_batch_size, valid_batch_size, test_batch_size),  #一样的话就是batch_size\n",
    "    sort=True,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: int(x.wordcount),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(len(train_iter), len(valid_iter), len(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> 1\n",
      ". 2\n",
      ", 3\n",
      "conclusion 4\n",
      "understand 129\n",
      "; 130\n",
      "chance 131\n",
      "extracurricular 132\n",
      "country 133\n",
      "taking 134\n",
      "big 135\n",
      "'re 136\n",
      "paragraph 137\n",
      "wrong 138\n",
      "classroom 139\n",
      "torch.Size([29751, 50])\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "for w, i in text_field.vocab.stoi.items():  #词和相应index\n",
    "    if 128 < ii < 140 or 0 < ii < 5:\n",
    "        print(w, i)\n",
    "    ii += 1\n",
    "    if ii == 141:\n",
    "        break\n",
    "print(text_field.vocab.vectors.shape)  #[29278, 50],共29278个词，每个词50维"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'type', 'ef', 'wordcount']\n"
     ]
    }
   ],
   "source": [
    "for i in train_iter:\n",
    "    print(i.input_fields)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model参数\n",
    "\n",
    "#embedding层\n",
    "embedding_shape = text_field.vocab.vectors.shape\n",
    "embedding_weight = text_field.vocab.vectors\n",
    "\n",
    "#lstm层\n",
    "hidden_size = 2\n",
    "num_layers = 1  #不太清楚设置成其他值怎么弄，下面的代码主要针对为1情况\n",
    "bidirectional = False  #是否双向lstm，双向的forward可能要变，初步考虑如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(*embedding_shape)\n",
    "        self.embedding.weight.data.copy_(embedding_weight)  #不能直接用=\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=text_field.vocab.vectors.shape[1],\n",
    "            batch_first=True,\n",
    "\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Linear(hidden_size, 3),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def __initHC__(self, batch_size):\n",
    "        self.H = torch.zeros([num_layers, batch_size, hidden_size])\n",
    "        self.C = torch.zeros([num_layers, batch_size, hidden_size])\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.embedding(x)\n",
    "\n",
    "        #self.__initHC__(batch_size = x.shape[0])\n",
    "        #x, (outH,outC) = self.lstm(x,(self.H,self.C))\n",
    "        x, (outH, outC) = self.lstm(x)\n",
    "\n",
    "        \"\"\"\n",
    "        if bidirectional:#不一定是这样\n",
    "            out = self.classifier(x[:,[-1],:] + x[:,[0],:])\n",
    "        else:\n",
    "            out = self.classifier(x[:,[-1],:])\n",
    "        \"\"\"\n",
    "        if bidirectional:  #不一定是这样\n",
    "            out = self.classifier(outH[0] + outH[0])\n",
    "        else:\n",
    "            out = self.classifier(outH[0])\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(model.embedding.parameters()).clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<CloneBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "model(list(train_iter)[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss等 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "#loss_func(pred_y,y)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=len(train_iter) * epochs + 10,\n",
    "    eta_min=1e-6\n",
    ")  #整个训练过程完成max->min"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    \"\"\"基本设置\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__pre_proc()\n",
    "\n",
    "    def __pre_proc(self):\n",
    "        model.to(device)\n",
    "\n",
    "        self.__init_loss()\n",
    "\n",
    "    def __init_loss(self):\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "\n",
    "    def get_loss(self, kind):\n",
    "        if kind == 'train':\n",
    "            return self.train_loss\n",
    "        elif kind == 'valid':\n",
    "            return self.valid_loss\n",
    "        else:\n",
    "            raise ValueError(\"kind值错误\")\n",
    "\n",
    "    def __save_model(self, epoch):\n",
    "        path = exp_dir + f\"/epoch_{epoch}_params.pkl\"\n",
    "        model_params = model.state_dict()\n",
    "        torch.save(model_params, path)\n",
    "\n",
    "    def set_model(self, epoch):\n",
    "        \"\"\"\n",
    "        从文件读出参数\n",
    "\n",
    "        Args:\n",
    "            epoch: 第几轮的参数\n",
    "        \"\"\"\n",
    "        path = exp_dir + f\"/epoch_{epoch}_params.pkl\"\n",
    "        model_params = torch.load(path)\n",
    "        model.load_state_dict(model_params)\n",
    "\n",
    "    \"\"\"训练相关\"\"\"\n",
    "\n",
    "    def train(self):\n",
    "        self.__init_loss()\n",
    "        for epoch in range(epochs):\n",
    "            self.train_one_epoch(epoch)\n",
    "            self.valid_one_epoch(epoch)\n",
    "\n",
    "            #self.__smw_proc(epoch)\n",
    "\n",
    "    def train_one_epoch(self, epoch):\n",
    "        model.train()\n",
    "\n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "        epoch_loss = 0  #统计本epoch的总loss，最后求平均loss\n",
    "        data_size = 0\n",
    "        pbar = tqdm(enumerate(train_iter), total=len(train_iter), desc=f'epoch_{epoch} train')\n",
    "        for i, batch in pbar:\n",
    "            x = batch.text\n",
    "            y = batch.ef\n",
    "\n",
    "            with amp.autocast():\n",
    "                predy = model(x)\n",
    "                batch_loss = loss_func(predy.squeeze(1), y)\n",
    "            scaler.scale(batch_loss).backward()\n",
    "\n",
    "            if i % 1 == 0:\n",
    "                scaler.step(optimizer)  #1个batch更新一次参数\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()  #同时更新lr\n",
    "\n",
    "            epoch_loss += float(batch_loss) * train_batch_size\n",
    "            data_size += train_batch_size\n",
    "\n",
    "            mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            pbar.set_postfix(\n",
    "                peoch_avg_loss=f'{epoch_loss / data_size:0.4f}',\n",
    "                lr=f'{current_lr:0.4f}',\n",
    "                gpu_mem=f'{mem:0.2f} GB'\n",
    "            )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        self.train_loss.append(epoch_loss / data_size)\n",
    "        self.__save_model(epoch)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valid_one_epoch(self, epoch):\n",
    "        model.eval()\n",
    "\n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "        epoch_loss = 0  #统计本epoch的总loss，最后求平均loss\n",
    "        data_size = 0\n",
    "        pbar = tqdm(enumerate(valid_iter), total=len(valid_iter), desc=f'epoch_{epoch} valid')\n",
    "        for i, batch in pbar:\n",
    "            x = batch.text\n",
    "            y = batch.ef\n",
    "\n",
    "            with amp.autocast():\n",
    "                predy = model(x)\n",
    "                batch_loss = loss_func(predy.squeeze(1), y)\n",
    "\n",
    "            epoch_loss += float(batch_loss) * valid_batch_size\n",
    "            data_size += valid_batch_size\n",
    "\n",
    "            mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "            pbar.set_postfix(\n",
    "                peoch_avg_loss=f'{epoch_loss / data_size:0.4f}',\n",
    "                gpu_mem=f'{mem:0.2f} GB'\n",
    "            )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        self.valid_loss.append(epoch_loss / data_size)\n",
    "\n",
    "    \"\"\"测试集\"\"\"\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        返回预测结果和loss\n",
    "        \"\"\"\n",
    "\n",
    "        temp = []  #存储结果\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "        cur_loss = 0\n",
    "        data_size = 0\n",
    "        pbar = tqdm(enumerate(test_iter), total=len(test_iter), desc='test')\n",
    "        for i, batch in pbar:\n",
    "            x = batch.text\n",
    "            y = batch.ef\n",
    "\n",
    "            with amp.autocast():\n",
    "                predy = model(x)\n",
    "                temp.append((predy.detach().cpu().numpy(), y.detach().cpu().numpy()))\n",
    "                batch_loss = loss_func(predy.squeeze(1), y)\n",
    "\n",
    "            cur_loss += float(batch_loss) * test_batch_size\n",
    "            data_size += test_batch_size\n",
    "\n",
    "            mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "            pbar.set_postfix(\n",
    "                loss=f'{cur_loss / data_size:0.4f}',\n",
    "                gpu_mem=f'{mem:0.2f} GB'\n",
    "            )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        res = []\n",
    "        for predy, y in temp:\n",
    "            for i in range(predy.shape[0]):\n",
    "                res.append((list(predy[i]), list(y[i])))\n",
    "\n",
    "        return cur_loss / data_size, res\n",
    "\n",
    "    \"\"\"可视化结果\"\"\"\n",
    "\n",
    "    def __smw_proc(self, epoch):\n",
    "\n",
    "        pass\n",
    "\n",
    "        with SummaryWriter(exp_name) as smw:\n",
    "            smw.add_scalars(\n",
    "                main_tag='datas/loss',\n",
    "                tag_scalar_dict={\n",
    "                    \"train_loss\": self.train_loss[f\"epoch_{epoch}\"],\n",
    "                    \"valid_loss\": self.valid_loss[f\"epoch_{epoch}\"],\n",
    "                },\n",
    "                global_step=epoch\n",
    "            )\n",
    "            smw.add_scalar(\n",
    "                tag='datas/lr',\n",
    "                scalar_value=optimizer.param_groups[0]['lr'],\n",
    "                global_step=epoch\n",
    "            )\n",
    "\n",
    "            imgs, masks, pred_masks = self.__get_show_result('train', 2)\n",
    "            for i in range(imgs.shape[0]):\n",
    "                dis_imgs = np.stack([i for i in imgs[i]] + [i for i in masks[i]] + [i for i in pred_masks[i]], axis=0)\n",
    "                dis_imgs = dis_imgs[:, np.newaxis]\n",
    "                self.smw.add_images(\n",
    "                    tag=f\"epoch_{epoch}/train/{i}\",\n",
    "                    img_tensor=dis_imgs\n",
    "                )\n",
    "            imgs, masks, pred_masks = self.__get_show_result('valid', 2)\n",
    "            for i in range(imgs.shape[0]):\n",
    "                dis_imgs = np.stack([i for i in imgs[i]] + [i for i in masks[i]] + [i for i in pred_masks[i]], axis=0)\n",
    "                dis_imgs = dis_imgs[:, np.newaxis]\n",
    "                smw.add_images(\n",
    "                    tag=f\"epoch_{epoch}/valid/{i}\",\n",
    "                    img_tensor=dis_imgs\n",
    "                )\n",
    "\n",
    "\n",
    "runner = Runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2034, 0.2028, 0.5938]], grad_fn=<SelectBackward>) tensor([0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 2, 2, 1, 0, 0, 2, 2, 2, 2, 1, 0,\n",
      "        1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "for batch in train_iter:\n",
    "    out = model(batch.text.to(device))\n",
    "    y = batch.ef\n",
    "    break\n",
    "print(out[0], y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}