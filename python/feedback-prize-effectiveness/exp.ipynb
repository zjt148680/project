{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题\n",
    "\n",
    "- [x] 长文本截断时尽量保留首尾，效果不怎么样。。。\n",
    "- [ ] 在上面的基础上考虑双向lstm\n",
    "- [x] 采用将类别添加到text头部的方式\n",
    "- [ ] summaryWriter版本问题\n",
    "- [x] 损失函数应为交叉损失，而不是BCELoss，这是用于多标签的\n",
    "- [x] iter可以被设置设备，所以训练时不用再to(device)，可以用batch.text.device查看是否正确。对于模型，next(model.parameters()).device\n",
    "- [x] ~~field有问题~~。预先数字化，再设置use_vocab=False\n",
    "- [ ] test相关代码还没写\n",
    "- [x] ~~生成iter时会将df的头部也当作数据传进处理中，所以会导致列名'type'也传进了处理函数中~~。data.TabularDataset(skip_header=True)\n",
    "- [ ] text生成有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.9.0+cpu\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: d:\\anaconda\\envs\\pytorch\\lib\\site-packages\n",
      "Requires: typing-extensions\n",
      "Required-by: efficientnet-pytorch, pretrainedmodels, timm, torchaudio, torchtext, torchvision\n",
      "---\n",
      "Name: torchtext\n",
      "Version: 0.10.0\n",
      "Summary: Text utilities and datasets for PyTorch\n",
      "Home-page: https://github.com/pytorch/text\n",
      "Author: PyTorch core devs and James Bradbury\n",
      "Author-email: jekbradbury@gmail.com\n",
      "License: BSD\n",
      "Location: d:\\anaconda\\envs\\pytorch\\lib\\site-packages\n",
      "Requires: numpy, requests, torch, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show torch torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle #变色\n",
    "%matplotlib inline\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy import data\n",
    "\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda import amp\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#from transformers import TrainingArguments,Trainer\n",
    "#from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "\n",
    "import os\n",
    "import re\n",
    "import gc #垃圾回收\n",
    "\n",
    "from tqdm import tqdm #进度条 for data in tqdm(range(100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"E:/DATA/feedback-prize-effectiveness/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   discourse_id      essay_id  \\\n",
      "0  0013cc385424  007ACE74B050   \n",
      "1  9704a709b505  007ACE74B050   \n",
      "2  c22adee811b6  007ACE74B050   \n",
      "3  a10d361e54e4  007ACE74B050   \n",
      "4  db3e453ec4e2  007ACE74B050   \n",
      "\n",
      "                                      discourse_text discourse_type  \\\n",
      "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
      "1  On my perspective, I think that the face is a ...       Position   \n",
      "2  I think that the face is a natural landform be...          Claim   \n",
      "3  If life was on Mars, we would know by now. The...       Evidence   \n",
      "4  People thought that the face was formed by ali...   Counterclaim   \n",
      "\n",
      "  discourse_effectiveness  \n",
      "0                Adequate  \n",
      "1                Adequate  \n",
      "2                Adequate  \n",
      "3                Adequate  \n",
      "4                Adequate  \n",
      "Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. \n",
      "36765\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(data_dir+\"train.csv\")\n",
    "print(df1.head())\n",
    "print(df1.iloc[0]['discourse_text'])\n",
    "print(len(df1))\n",
    "#essay_id   txt文件名\n",
    "#discourse_id   段落的id，应该没用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_id               0\n",
       "essay_id                   0\n",
       "discourse_text             0\n",
       "discourse_type             0\n",
       "discourse_effectiveness    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concluding Statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Counterclaim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rebuttal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         discourse_type\n",
       "0                 Claim\n",
       "1  Concluding Statement\n",
       "2          Counterclaim\n",
       "3              Evidence\n",
       "4                  Lead\n",
       "5              Position\n",
       "6              Rebuttal"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['discourse_type']].apply(np.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ineffective</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  discourse_effectiveness\n",
       "0                Adequate\n",
       "1               Effective\n",
       "2             Ineffective"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['discourse_effectiveness']].apply(np.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   discourse_id      essay_id  \\\n",
      "0  a261b6e14276  D72CB1C11673   \n",
      "1  5a88900e7dc1  D72CB1C11673   \n",
      "2  9790d835736b  D72CB1C11673   \n",
      "3  75ce6d68b67b  D72CB1C11673   \n",
      "4  93578d946723  D72CB1C11673   \n",
      "\n",
      "                                      discourse_text discourse_type  \n",
      "0  Making choices in life can be very difficult. ...           Lead  \n",
      "1  Seeking multiple opinions can help a person ma...       Position  \n",
      "2                     it can decrease stress levels           Claim  \n",
      "3             a great chance to learn something new           Claim  \n",
      "4               can be very helpful and beneficial.           Claim  \n",
      "Making choices in life can be very difficult. People often ask for advice when they can not decide on one thing. It's always good to ask others for their advice when making a choice. When you have multiple opinions you have the ability to make the best choice for yourself. \n",
      "10\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(data_dir+\"test.csv\")\n",
    "print(df2.head())\n",
    "print(df2.iloc[0]['discourse_text'])\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_id      0\n",
       "essay_id          0\n",
       "discourse_text    0\n",
       "discourse_type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear: Principal\n",
      "\n",
      "I am arguing against the policy change because even though there are some children out there that really needs help with their academic work, that does not mean that only because they have a c average that would not let them enjoy their sports or other activities unless they've a B average.\n",
      "\n",
      "Sometimes teachers or even principal needs to consider that we should give the help that any student should have. Also this may consider student self as steam. Meaning student would start to feel sad nervous, and not wanting to go to school because of the reason they have a low averages and they can not participate in other activities or sports. The fact that there are children that would want to enjoy many good things the school is actually giving it to them.\n",
      "\n",
      "We would want to make changes as, \"like to be a better person for a better tomorrow\" This supports the idea of having have many good thoughts and incasing your work as much as possible. In some situation like arguing we should make a vote to see if kids would want to have a school policy of change and having to participate in fun activities but they first need to have at least a B average. Some reasons I would be against the school policy change is because you would feel ashame and then many bad things could happen meaning, you would be angry etc. In additionally , I think that student should have sports because it helps them with their health, and problems that they would have personal. I am against this policy change.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Student.\n",
      "-------\n",
      "Dear Florida senator,\n",
      "\n",
      "I would like disuss why changing up the way we voyte today is not as bad f an idea as it sounds. Changing to elections by a popular vote sounds like its in the peoples hands instead of juts casting out votes on the slate electors. Aren't we voting for our president. innstead of countting onn the electoral votes to hep out or, go against out favor, it'd be much more easier to just let the people vote.\n",
      "\n",
      "The elctoral votes are utterly useless or unimportant,though. If there is ever happens to be a tie between the two candidates the electoral votes can help break it. It'd be less of a hassle to have the florida residents vote,directly, on someone besides the president. Less worring about if theyre going to win or not. Now when you start to think about it the electoral college is just unfair an pretty outdated,if you ask me. Change doesn't sound that bad. All im trying to achive by writting this, is to gain actual control over who we're all voting for.\n",
      "\n",
      "It's also not just what's completely wrong with the electoral college but how does it help in the first place? When you start analizing it, it really doens't help much. How much actual help can the lectora coellge make, in my defense not much. Why? Simple, its just 20-30 more votes and not many states have that much Hawaii has uop to 4 electoral votes, not much. Voters should be alowed to directly vote for who they want to be president and not rely on the lectoral college.    \n"
     ]
    }
   ],
   "source": [
    "with open(data_dir+\"/train/000E6DE9E817.txt\") as f:\n",
    "    print(f.read())\n",
    "print(\"-------\")\n",
    "with open(data_dir+\"/train/00B144412785.txt\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 1 44.75033319733442 28.0\n"
     ]
    }
   ],
   "source": [
    "df1['wordcount'] = df1['discourse_text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    "    )\n",
    "print(\n",
    "    np.max(df1['wordcount']),np.min(df1['wordcount']),\n",
    "    np.average(df1['wordcount']),np.median(df1['wordcount'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(221)\n",
    "plt.hist(x = list(df1['wordcount']),bins=80)\n",
    "plt.subplot(222)\n",
    "plt.hist(x = list(df1[df1['wordcount']<=200]['wordcount']),bins=40)\n",
    "plt.subplot(223)\n",
    "plt.bar(x = [0,1], height = [len(df1[df1['wordcount']<=50]),len(df1[df1['wordcount']>50])])\n",
    "plt.subplot(224)\n",
    "plt.bar(x = [0,1], height = [len(df1[df1['wordcount']<=128]),len(df1[df1['wordcount']>128])])\n",
    "plt.show()\n",
    "\n",
    "#考虑到这是论述文，所以开头结尾比较重要，数据处理时需要考虑到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cc921c5cfda4</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>stress.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>1ab1030c639a</td>\n",
       "      <td>0A5B8761B187</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Position</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>210f8f088aa4</td>\n",
       "      <td>1B4E66B0BE0A</td>\n",
       "      <td>pollution.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>e18b753a740a</td>\n",
       "      <td>1DC6485ABFF6</td>\n",
       "      <td>interest,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>91b5849cdbed</td>\n",
       "      <td>1DC6485ABFF6</td>\n",
       "      <td>funds/workers.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>6826ef3d5b63</td>\n",
       "      <td>34C979F3ABAA</td>\n",
       "      <td>promoting</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>461645ee618c</td>\n",
       "      <td>34C979F3ABAA</td>\n",
       "      <td>protection</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>439210ca27fb</td>\n",
       "      <td>34C979F3ABAA</td>\n",
       "      <td>bills</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>aa83e041a0aa</td>\n",
       "      <td>3E866ECC376A</td>\n",
       "      <td>enthusiastic,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Effective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4539</th>\n",
       "      <td>8ced2bb31129</td>\n",
       "      <td>50F1D8786126</td>\n",
       "      <td>emotions</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      discourse_id      essay_id   discourse_text discourse_type  \\\n",
       "11    cc921c5cfda4  00944C693682         stress.           Claim   \n",
       "452   1ab1030c639a  0A5B8761B187        Disagree        Position   \n",
       "1397  210f8f088aa4  1B4E66B0BE0A      pollution.           Claim   \n",
       "1571  e18b753a740a  1DC6485ABFF6       interest,           Claim   \n",
       "1572  91b5849cdbed  1DC6485ABFF6  funds/workers.           Claim   \n",
       "2907  6826ef3d5b63  34C979F3ABAA       promoting           Claim   \n",
       "2908  461645ee618c  34C979F3ABAA      protection           Claim   \n",
       "2909  439210ca27fb  34C979F3ABAA           bills           Claim   \n",
       "3456  aa83e041a0aa  3E866ECC376A   enthusiastic,           Claim   \n",
       "4539  8ced2bb31129  50F1D8786126        emotions           Claim   \n",
       "\n",
       "     discourse_effectiveness  wordcount  \n",
       "11                  Adequate          1  \n",
       "452              Ineffective          1  \n",
       "1397                Adequate          1  \n",
       "1571             Ineffective          1  \n",
       "1572             Ineffective          1  \n",
       "2907             Ineffective          1  \n",
       "2908                Adequate          1  \n",
       "2909                Adequate          1  \n",
       "3456               Effective          1  \n",
       "4539                Adequate          1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['wordcount']==1].head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "## 数据基本处理\n",
    "1. 一般语言处理中对全部数据只会取常用的n个词，在此之外的词是不认识的，即先有一本字典\n",
    "2. 用one-hot编码时，每个词都表示为长n的向量，其中只有一个值是1，其余全是0。比如字典的第i（0开始）个单词其编码中1值的下标是i\n",
    "\n",
    "## embedding\n",
    "1. one_hot编码稀疏，所以考虑用稠密向量表示词，比如只用长为m<n的向量表示n个单词，其中单词间关系可以体现在向量间关系中，比如$\\vec{男}+\\vec{国王}=\\vec{皇帝}$\n",
    "2. 可由embedding层实现这个，embedding记录了一个(n,m)的矩阵，每行都是一个单词的稠密向量，作用是one-hot编码的向量按照其1值的下标i访问这个矩阵第i行，取出这行向量作为新输入\n",
    "3. 具体使用看下面代码说明\n",
    "4. embedding可由自行训练出，也可预加载预训练参数。使用预训练参数时，冻结此层\n",
    "\n",
    "## 初步结果\n",
    "将batch_size\\*len_sentences\\*n变为batch_size\\*len_sentences\\*m\n",
    "\n",
    "## rnn具体流程\n",
    "1. 首先初始化hadden_input为全0\n",
    "2. 对每个词，其都会和当前的hadden_input一起进入网络(cat或add)进行一步（liner、tanh激活）运算，所得的输出作为新的hadden_input与下一个词的向量一起进入网络（cat或add）\n",
    "3. cat（最后一维）的话，需要截断，或者另外卷积一次获得新hadden_input\n",
    "4. pytorch的rnn为x[i]通过一liner，hidden通过一liner，两个结果相加经Tanh激活，结果作为x[i]和新hidden，具体见下面代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before embedding:torch.Size([4, 20])\n",
      "after embedding:torch.Size([4, 20, 8])\n",
      "-------------\n",
      "rnn input:torch.Size([20, 4, 8])\n",
      "rnn out:torch.Size([20, 4, 128])\n",
      "rnn outh:torch.Size([4, 128])\n",
      "-----------\n",
      "finally shape:torch.Size([4, 2])\n",
      "tensor([[0.5867, 0.4133],\n",
      "        [0.3925, 0.6075],\n",
      "        [0.4375, 0.5625],\n",
      "        [0.4605, 0.5395]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# rnn内部细节\n",
    "batch_size = 4\n",
    "sentence_len = 20 #一句话20个词\n",
    "words_num = 100 #字典记录了100个词\n",
    "vector_len = 8 #字典的每个词向量长8\n",
    "X = torch.randint(0,words_num,[batch_size,sentence_len]) #注意输入不为one-hot，只是每个词的字典序号，比如[3,2,10]表示一句话。int\n",
    "y = torch.as_tensor([[0.,1],[0,1],[1,0],[1,0]])\n",
    "#print(X)\n",
    "\n",
    "hidden_layer_num = 1 #多少个hidden用于循环，即多少个循环部分\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = 128\n",
    "        self.embedding_layer = nn.Embedding(words_num,vector_len,padding_idx=0) #100*8,padding_idx为输入长度不够时填充的字典词序号\n",
    "\n",
    "        #一个循环节\n",
    "        self.hidden_layer_x = nn.Linear(vector_len,self.hidden_size) #rnn关键部分\n",
    "        self.hidden_layer_h = nn.Linear(self.hidden_size,self.hidden_size) #给h用\n",
    "\n",
    "        #分类器\n",
    "        self.out_layer = nn.Linear(self.hidden_size,2)\n",
    "        self.activation_layer = nn.Softmax(dim=-1) #dim=0表示a[i][j][k]按i方向的几个数一起算\n",
    "\n",
    "    def __init_hidden(self):\n",
    "        return torch.zeros([hidden_layer_num,batch_size,self.hidden_size])\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.hidden = self.__init_hidden()\n",
    "\n",
    "        print(f\"before embedding:{x.shape}\") #[4, 20]\n",
    "        x = self.embedding_layer(x)\n",
    "        print(f\"after embedding:{x.shape}\") #[4, 20, 8]\n",
    "        print(\"-------------\")\n",
    "\n",
    "        out = torch.zeros([sentence_len, batch_size, self.hidden_size])\n",
    "\n",
    "        #rnn部分\n",
    "        # 为了更好计算，将数据x变形为为len_sencentces*batch_size*words_num\n",
    "        # 即x[0]为各句子首单词\n",
    "        x = x.transpose(0,1)\n",
    "        print(f\"rnn input:{x.shape}\") #[20, 4, 128]\n",
    "        for i in range(x.shape[0]):\n",
    "            a1 = self.hidden_layer_x(x[i])\n",
    "            a2 = self.hidden_layer_h(self.hidden[0])\n",
    "\n",
    "            out[i] = self.hidden[0] = nn.Tanh()(a1+a2)\n",
    "        print(f\"rnn out:{out.shape}\")\n",
    "        print(f\"rnn outh:{self.hidden[0].shape}\")\n",
    "        print(\"-----------\")\n",
    "        \n",
    "        #分类器\n",
    "        o = self.hidden[0]#即out[x.shape[0]-1]\n",
    "        o = self.out_layer(o)\n",
    "        o = self.activation_layer(o)\n",
    "        print(f\"finally shape:{o.shape}\") #[4, 2]\n",
    "        print(o)\n",
    "\n",
    "        return o\n",
    "\n",
    "rnn = MyRNN()\n",
    "out = rnn(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch的rnn\n",
    "- 首先就是输入是batch_size\\*len_sencentces\\*words_num  \n",
    "所以Embedding算是预处理部分，如果需要训练则？？？？？？？？\n",
    "- 主要公式$$h_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 8])\n",
      "torch.Size([2, 5, 32]) torch.Size([1, 2, 32])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "sentence_len = 5\n",
    "words_num = 10\n",
    "words_len = 8\n",
    "\n",
    "X = torch.randint(0,words_num,[batch_size,sentence_len])\n",
    "\n",
    "X = nn.Embedding(words_num,words_len)(X)\n",
    "#X = X.transpose(0,1) #batch_size放在第二维，则batch_first设置为False\n",
    "print(X.shape)\n",
    "\n",
    "hidden_size=32\n",
    "num_layers=1\n",
    "H = torch.zeros([num_layers,batch_size,hidden_size]) #可以不设置，则默认为0，这是单向rnn\n",
    "#HH = torch.zeros([num_layers*2,batch_size,hidden_size]) #双向rnn，需要RNN中设置bidirectional=True\n",
    "\n",
    "rnn = nn.RNN(\n",
    "            input_size=words_len,\n",
    "\n",
    "            #hidden_size，num_layers 都是对网络的设置，与输入数据无关，设置相对自由\n",
    "            hidden_size=hidden_size,     # hidden层大小\n",
    "            num_layers=num_layers,       # n个rnn层\n",
    "\n",
    "            batch_first=True, #True则输入输出的batch在第一维，否则在第二维（参照上面MyRNN在hidden前的变形）\n",
    "\n",
    "            bidirectional=False, #是否双向rnn\n",
    "        )\n",
    "\n",
    "out,outh = rnn(X,H) #out为h的集合\n",
    "print(out.shape,outh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([32, 8]) <class 'torch.nn.parameter.Parameter'>\n",
      "weight_hh_l0 torch.Size([32, 32]) <class 'torch.nn.parameter.Parameter'>\n",
      "bias_ih_l0 torch.Size([32]) <class 'torch.nn.parameter.Parameter'>\n",
      "bias_hh_l0 torch.Size([32]) <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for i in rnn.named_parameters():\n",
    "    print(i[0],i[1].shape,type(i[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 4])\n",
      "pytorch部分\n",
      "torch.Size([2, 5, 8]) torch.Size([1, 2, 8])\n",
      "tensor([-0.7137,  0.5926, -0.6244,  0.6198, -0.1706, -0.5207, -0.0612,  0.4735],\n",
      "       grad_fn=<SliceBackward>) \n",
      " tensor([-0.8456,  0.2111,  0.1764,  0.7712, -0.0146, -0.7987, -0.6467,  0.7652],\n",
      "       grad_fn=<SliceBackward>)\n",
      "-------------------\n",
      "MyCNN部分\n",
      "torch.Size([2, 5, 8]) torch.Size([1, 2, 8])\n",
      "tensor([-0.7137,  0.5926, -0.6244,  0.6198, -0.1706, -0.5207, -0.0612,  0.4735],\n",
      "       grad_fn=<SliceBackward>) \n",
      " tensor([-0.8456,  0.2111,  0.1764,  0.7712, -0.0146, -0.7987, -0.6467,  0.7652],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1024)\n",
    "\n",
    "batch_size = 2\n",
    "sentence_len = 5\n",
    "words_num = 10\n",
    "vector_len = 4\n",
    "\n",
    "hidden_size=8\n",
    "num_layers=1\n",
    "\n",
    "X = torch.randint(0,words_num,(batch_size,sentence_len))\n",
    "em = nn.Embedding(words_num,vector_len)\n",
    "X = em(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('pytorch部分')\n",
    "rnn = nn.RNN(\n",
    "            input_size=vector_len,\n",
    "\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "\n",
    "            batch_first=True,\n",
    "        )\n",
    "out,outh = rnn(X)\n",
    "print(out.shape,outh.shape)\n",
    "print(outh[0,0,:],'\\n',out[0,0,:])\n",
    "print('-------------------')\n",
    "\n",
    "\n",
    "print('MyCNN部分')\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.hidden_layer_x = nn.Linear(vector_len,hidden_size) #rnn关键部分\n",
    "        self.hidden_layer_h = nn.Linear(hidden_size,hidden_size) #h用\n",
    "\n",
    "        #注意这里无条件复制w、b，所以最好先判断两者形状相等再赋值\n",
    "        params = list(rnn.parameters())\n",
    "        assert self.hidden_layer_x.weight.shape == params[0].shape and \\\n",
    "                self.hidden_layer_h.weight.shape == params[1].shape and \\\n",
    "                self.hidden_layer_x.bias.shape == params[2].shape and \\\n",
    "                self.hidden_layer_h.bias.shape == params[3].shape,\\\n",
    "                print(\"shape error\")\n",
    "\n",
    "        self.hidden_layer_x.weight = params[0]\n",
    "        self.hidden_layer_h.weight = params[1]\n",
    "        self.hidden_layer_x.bias = params[2]\n",
    "        self.hidden_layer_h.bias = params[3]\n",
    "\n",
    "    def __init_hidden(self):\n",
    "        return torch.zeros([num_layers,batch_size,hidden_size])\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.hidden = self.__init_hidden()\n",
    "\n",
    "        out = torch.zeros([sentence_len,batch_size,hidden_size])\n",
    "\n",
    "        x = x.transpose(0,1)\n",
    "        for i in range(x.shape[0]):\n",
    "            a1 = self.hidden_layer_x(x[i])\n",
    "            a2 = self.hidden_layer_h(self.hidden[0])\n",
    "            self.hidden[0] = nn.Tanh()(a1+a2)\n",
    "\n",
    "\n",
    "            out[i] = self.hidden[0]\n",
    "\n",
    "        return out.transpose(0,1)\n",
    "\n",
    "myrnn = MyRNN()\n",
    "out = myrnn(X)\n",
    "print(out.shape,myrnn.hidden.shape)\n",
    "print(myrnn.hidden[0,0,:],'\\n',out[0,0,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "## 基本理解\n",
    "- rnn因为激活层是Tanh，显然，当前信息几乎不会对很远的计算产生影响，即只能短期记忆\n",
    "- lstm中引入可以选择“记忆”和“当前”的信息对当前输出的占比 \n",
    "## 具体介绍 \n",
    "- 输入是H（类似于rnn的hidden作用），C（当前记忆）\n",
    "- 一个单元分为记忆门，遗忘门，rnn门，输出门，其相当于四次rnn变换，只不过功能和激活函数不同\n",
    "   - 记忆门i，Sigmoid激活，即当前rnn输出需要记哪些信息到记忆C中\n",
    "   - 遗忘门f，Sigmoid激活，即原先记忆需要遗忘哪些信息\n",
    "   - rnn门g，Tanh激活，就是rnn\n",
    "   - 输出门o，Sigmoid激活，控制新记忆哪些作为新H\n",
    "- 公式如下\n",
    "$$\n",
    "    \\begin{array}{ll} \\\\\n",
    "        i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
    "        f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
    "        g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n",
    "        o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
    "        c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
    "        h_t = o_t \\odot \\tanh(c_t) \\\\\n",
    "    \\end{array}\n",
    "$$\n",
    "## pytorch内部细节\n",
    "- 将四个变换按维度一放在一起，同时计算四个门激活前的输出，输出顺序如上顺序，见如下代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 4])\n",
      "pytorch部分\n",
      "torch.Size([2, 5, 16]) torch.Size([1, 2, 16]) torch.Size([1, 2, 16])\n",
      "tensor([ 0.0842,  0.0372, -0.1389,  0.0300, -0.1425,  0.0223,  0.0017,  0.3239,\n",
      "        -0.0413, -0.0924, -0.1835,  0.0621,  0.0484, -0.0894,  0.2133,  0.0063],\n",
      "       grad_fn=<SliceBackward>)\n",
      "-------------------\n",
      "MyLSTM部分\n",
      "torch.Size([2, 5, 16]) torch.Size([1, 2, 16]) torch.Size([1, 2, 16])\n",
      "tensor([ 0.0842,  0.0372, -0.1389,  0.0300, -0.1425,  0.0223,  0.0017,  0.3239,\n",
      "        -0.0413, -0.0924, -0.1835,  0.0621,  0.0484, -0.0894,  0.2133,  0.0063],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1024)\n",
    "\n",
    "batch_size = 2\n",
    "sentence_len = 5\n",
    "words_num = 10\n",
    "words_len = 4\n",
    "\n",
    "hidden_size=16\n",
    "num_layers=1\n",
    "\n",
    "X = torch.randint(0,words_num,(batch_size,sentence_len))\n",
    "em = nn.Embedding(words_num,words_len)\n",
    "X = em(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('pytorch部分')\n",
    "lstm = nn.LSTM(\n",
    "            input_size=words_len,\n",
    "\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "\n",
    "            batch_first=True,\n",
    "        )\n",
    "H = torch.zeros([num_layers,batch_size,hidden_size])\n",
    "C = torch.zeros([num_layers,batch_size,hidden_size])\n",
    "out,(outh,outc) = lstm(X,(H,C)) #H、C默认为0\n",
    "print(out.shape,outh.shape,outc.shape)\n",
    "print(out[0,0,:])\n",
    "print('-------------------')\n",
    "\n",
    "\n",
    "print('MyLSTM部分')\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layer_x = nn.Linear(words_len,hidden_size*4) #4*32，即同时输出4组\n",
    "        self.hidden_layer_h = nn.Linear(hidden_size,hidden_size*4) #8*32\n",
    "\n",
    "        params = list(lstm.parameters())\n",
    "        assert self.hidden_layer_x.weight.shape == params[0].shape and \\\n",
    "                self.hidden_layer_h.weight.shape == params[1].shape and \\\n",
    "                self.hidden_layer_x.bias.shape == params[2].shape and \\\n",
    "                self.hidden_layer_h.bias.shape == params[3].shape, \\\n",
    "                print(\"shape error\")\n",
    "\n",
    "        self.hidden_layer_x.weight = params[0]\n",
    "        self.hidden_layer_h.weight = params[1]\n",
    "        self.hidden_layer_x.bias = params[2]\n",
    "        self.hidden_layer_h.bias = params[3]\n",
    "\n",
    "    def __init_H_C(self):\n",
    "        return torch.zeros([num_layers,batch_size,hidden_size]),\\\n",
    "                torch.zeros([num_layers,batch_size,hidden_size])\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.H,self.C = self.__init_H_C()\n",
    "        #H是输出\n",
    "        #C是记忆\n",
    "\n",
    "        out = torch.zeros([sentence_len,batch_size,hidden_size])\n",
    "\n",
    "        x = x.transpose(0,1)\n",
    "        for i in torch.arange(x.shape[0]):\n",
    "\n",
    "            a1 = self.hidden_layer_x(x[i])\n",
    "            a2 = self.hidden_layer_h(self.H[0])\n",
    "            a = a1+a2\n",
    "\n",
    "            remember_gate = nn.Sigmoid()(a[:,:hidden_size*1]) #记住下面op什么信息\n",
    "            forget_gate = nn.Sigmoid()(a[:,hidden_size*1:hidden_size*2]) #C遗忘什么信息\n",
    "            op = nn.Tanh()(a[:,hidden_size*2:hidden_size*3])\n",
    "            output_gate = nn.Sigmoid()(a[:,hidden_size*3:]) #最终输出\n",
    "\t\t\t\n",
    "            self.C[0] = self.C[0]*forget_gate + remember_gate*op #新的记忆\n",
    "            self.H[0] = nn.Tanh()(self.C)*output_gate #生成新的输出\n",
    "\n",
    "            out[i] = self.H[0]\n",
    "\n",
    "        return out.transpose(0,1)\n",
    "\n",
    "mylstm = MyLSTM()\n",
    "out = mylstm(X)\n",
    "print(out.shape,mylstm.C.shape,mylstm.H.shape)\n",
    "print(out[0,0,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化\n",
    "- 遗忘门=1-记忆门，减少运算次数\n",
    "- 。。。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~transformers~~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\project\\python\\feedback-prize-effectiveness\\exp.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m question_answerer \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mquestion-answering\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m#内部有模型，用于回答问题的\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m context \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mExtractive Question Answering is the task of extracting an answer from a text given a question. An example of a\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mquestion answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39ma model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\import_utils.py:1083\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1081\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[0;32m   1082\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m-> 1083\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[0;32m   1084\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1085\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\import_utils.py:1093\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_module\u001b[39m(\u001b[39mself\u001b[39m, module_name: \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1092\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1093\u001b[0m         \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m   1094\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1095\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1096\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1097\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1098\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\pipelines\\__init__.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdynamic_module_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_class_from_dynamic_module\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[1;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfiguration_auto\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoConfig\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction_auto\u001b[39;00m \u001b[39mimport\u001b[39;00m FEATURE_EXTRACTOR_MAPPING, AutoFeatureExtractor\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_auto\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForDepthEstimation\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\__init__.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     albert,\n\u001b[0;32m     21\u001b[0m     audio_spectrogram_transformer,\n\u001b[0;32m     22\u001b[0m     auto,\n\u001b[0;32m     23\u001b[0m     bart,\n\u001b[0;32m     24\u001b[0m     barthez,\n\u001b[0;32m     25\u001b[0m     bartpho,\n\u001b[0;32m     26\u001b[0m     beit,\n\u001b[0;32m     27\u001b[0m     bert,\n\u001b[0;32m     28\u001b[0m     bert_generation,\n\u001b[0;32m     29\u001b[0m     bert_japanese,\n\u001b[0;32m     30\u001b[0m     bertweet,\n\u001b[0;32m     31\u001b[0m     big_bird,\n\u001b[0;32m     32\u001b[0m     bigbird_pegasus,\n\u001b[0;32m     33\u001b[0m     blenderbot,\n\u001b[0;32m     34\u001b[0m     blenderbot_small,\n\u001b[0;32m     35\u001b[0m     bloom,\n\u001b[0;32m     36\u001b[0m     bort,\n\u001b[0;32m     37\u001b[0m     byt5,\n\u001b[0;32m     38\u001b[0m     camembert,\n\u001b[0;32m     39\u001b[0m     canine,\n\u001b[0;32m     40\u001b[0m     chinese_clip,\n\u001b[0;32m     41\u001b[0m     clip,\n\u001b[0;32m     42\u001b[0m     clipseg,\n\u001b[0;32m     43\u001b[0m     codegen,\n\u001b[0;32m     44\u001b[0m     conditional_detr,\n\u001b[0;32m     45\u001b[0m     convbert,\n\u001b[0;32m     46\u001b[0m     convnext,\n\u001b[0;32m     47\u001b[0m     cpm,\n\u001b[0;32m     48\u001b[0m     ctrl,\n\u001b[0;32m     49\u001b[0m     cvt,\n\u001b[0;32m     50\u001b[0m     data2vec,\n\u001b[0;32m     51\u001b[0m     deberta,\n\u001b[0;32m     52\u001b[0m     deberta_v2,\n\u001b[0;32m     53\u001b[0m     decision_transformer,\n\u001b[0;32m     54\u001b[0m     deformable_detr,\n\u001b[0;32m     55\u001b[0m     deit,\n\u001b[0;32m     56\u001b[0m     detr,\n\u001b[0;32m     57\u001b[0m     dialogpt,\n\u001b[0;32m     58\u001b[0m     dinat,\n\u001b[0;32m     59\u001b[0m     distilbert,\n\u001b[0;32m     60\u001b[0m     dit,\n\u001b[0;32m     61\u001b[0m     donut,\n\u001b[0;32m     62\u001b[0m     dpr,\n\u001b[0;32m     63\u001b[0m     dpt,\n\u001b[0;32m     64\u001b[0m     electra,\n\u001b[0;32m     65\u001b[0m     encoder_decoder,\n\u001b[0;32m     66\u001b[0m     ernie,\n\u001b[0;32m     67\u001b[0m     esm,\n\u001b[0;32m     68\u001b[0m     flaubert,\n\u001b[0;32m     69\u001b[0m     flava,\n\u001b[0;32m     70\u001b[0m     fnet,\n\u001b[0;32m     71\u001b[0m     fsmt,\n\u001b[0;32m     72\u001b[0m     funnel,\n\u001b[0;32m     73\u001b[0m     glpn,\n\u001b[0;32m     74\u001b[0m     gpt2,\n\u001b[0;32m     75\u001b[0m     gpt_neo,\n\u001b[0;32m     76\u001b[0m     gpt_neox,\n\u001b[0;32m     77\u001b[0m     gpt_neox_japanese,\n\u001b[0;32m     78\u001b[0m     gptj,\n\u001b[0;32m     79\u001b[0m     groupvit,\n\u001b[0;32m     80\u001b[0m     herbert,\n\u001b[0;32m     81\u001b[0m     hubert,\n\u001b[0;32m     82\u001b[0m     ibert,\n\u001b[0;32m     83\u001b[0m     imagegpt,\n\u001b[0;32m     84\u001b[0m     jukebox,\n\u001b[0;32m     85\u001b[0m     layoutlm,\n\u001b[0;32m     86\u001b[0m     layoutlmv2,\n\u001b[0;32m     87\u001b[0m     layoutlmv3,\n\u001b[0;32m     88\u001b[0m     layoutxlm,\n\u001b[0;32m     89\u001b[0m     led,\n\u001b[0;32m     90\u001b[0m     levit,\n\u001b[0;32m     91\u001b[0m     lilt,\n\u001b[0;32m     92\u001b[0m     longformer,\n\u001b[0;32m     93\u001b[0m     longt5,\n\u001b[0;32m     94\u001b[0m     luke,\n\u001b[0;32m     95\u001b[0m     lxmert,\n\u001b[0;32m     96\u001b[0m     m2m_100,\n\u001b[0;32m     97\u001b[0m     marian,\n\u001b[0;32m     98\u001b[0m     markuplm,\n\u001b[0;32m     99\u001b[0m     maskformer,\n\u001b[0;32m    100\u001b[0m     mbart,\n\u001b[0;32m    101\u001b[0m     mbart50,\n\u001b[0;32m    102\u001b[0m     mctct,\n\u001b[0;32m    103\u001b[0m     megatron_bert,\n\u001b[0;32m    104\u001b[0m     megatron_gpt2,\n\u001b[0;32m    105\u001b[0m     mluke,\n\u001b[0;32m    106\u001b[0m     mmbt,\n\u001b[0;32m    107\u001b[0m     mobilebert,\n\u001b[0;32m    108\u001b[0m     mobilenet_v1,\n\u001b[0;32m    109\u001b[0m     mobilenet_v2,\n\u001b[0;32m    110\u001b[0m     mobilevit,\n\u001b[0;32m    111\u001b[0m     mpnet,\n\u001b[0;32m    112\u001b[0m     mt5,\n\u001b[0;32m    113\u001b[0m     mvp,\n\u001b[0;32m    114\u001b[0m     nat,\n\u001b[0;32m    115\u001b[0m     nezha,\n\u001b[0;32m    116\u001b[0m     nllb,\n\u001b[0;32m    117\u001b[0m     nystromformer,\n\u001b[0;32m    118\u001b[0m     openai,\n\u001b[0;32m    119\u001b[0m     opt,\n\u001b[0;32m    120\u001b[0m     owlvit,\n\u001b[0;32m    121\u001b[0m     pegasus,\n\u001b[0;32m    122\u001b[0m     pegasus_x,\n\u001b[0;32m    123\u001b[0m     perceiver,\n\u001b[0;32m    124\u001b[0m     phobert,\n\u001b[0;32m    125\u001b[0m     plbart,\n\u001b[0;32m    126\u001b[0m     poolformer,\n\u001b[0;32m    127\u001b[0m     prophetnet,\n\u001b[0;32m    128\u001b[0m     qdqbert,\n\u001b[0;32m    129\u001b[0m     rag,\n\u001b[0;32m    130\u001b[0m     realm,\n\u001b[0;32m    131\u001b[0m     reformer,\n\u001b[0;32m    132\u001b[0m     regnet,\n\u001b[0;32m    133\u001b[0m     rembert,\n\u001b[0;32m    134\u001b[0m     resnet,\n\u001b[0;32m    135\u001b[0m     retribert,\n\u001b[0;32m    136\u001b[0m     roberta,\n\u001b[0;32m    137\u001b[0m     roc_bert,\n\u001b[0;32m    138\u001b[0m     roformer,\n\u001b[0;32m    139\u001b[0m     segformer,\n\u001b[0;32m    140\u001b[0m     sew,\n\u001b[0;32m    141\u001b[0m     sew_d,\n\u001b[0;32m    142\u001b[0m     speech_encoder_decoder,\n\u001b[0;32m    143\u001b[0m     speech_to_text,\n\u001b[0;32m    144\u001b[0m     speech_to_text_2,\n\u001b[0;32m    145\u001b[0m     splinter,\n\u001b[0;32m    146\u001b[0m     squeezebert,\n\u001b[0;32m    147\u001b[0m     swin,\n\u001b[0;32m    148\u001b[0m     swinv2,\n\u001b[0;32m    149\u001b[0m     switch_transformers,\n\u001b[0;32m    150\u001b[0m     t5,\n\u001b[0;32m    151\u001b[0m     table_transformer,\n\u001b[0;32m    152\u001b[0m     tapas,\n\u001b[0;32m    153\u001b[0m     tapex,\n\u001b[0;32m    154\u001b[0m     time_series_transformer,\n\u001b[0;32m    155\u001b[0m     trajectory_transformer,\n\u001b[0;32m    156\u001b[0m     transfo_xl,\n\u001b[0;32m    157\u001b[0m     trocr,\n\u001b[0;32m    158\u001b[0m     unispeech,\n\u001b[0;32m    159\u001b[0m     unispeech_sat,\n\u001b[0;32m    160\u001b[0m     van,\n\u001b[0;32m    161\u001b[0m     videomae,\n\u001b[0;32m    162\u001b[0m     vilt,\n\u001b[0;32m    163\u001b[0m     vision_encoder_decoder,\n\u001b[0;32m    164\u001b[0m     vision_text_dual_encoder,\n\u001b[0;32m    165\u001b[0m     visual_bert,\n\u001b[0;32m    166\u001b[0m     vit,\n\u001b[0;32m    167\u001b[0m     vit_mae,\n\u001b[0;32m    168\u001b[0m     vit_msn,\n\u001b[0;32m    169\u001b[0m     wav2vec2,\n\u001b[0;32m    170\u001b[0m     wav2vec2_conformer,\n\u001b[0;32m    171\u001b[0m     wav2vec2_phoneme,\n\u001b[0;32m    172\u001b[0m     wav2vec2_with_lm,\n\u001b[0;32m    173\u001b[0m     wavlm,\n\u001b[0;32m    174\u001b[0m     whisper,\n\u001b[0;32m    175\u001b[0m     x_clip,\n\u001b[0;32m    176\u001b[0m     xglm,\n\u001b[0;32m    177\u001b[0m     xlm,\n\u001b[0;32m    178\u001b[0m     xlm_prophetnet,\n\u001b[0;32m    179\u001b[0m     xlm_roberta,\n\u001b[0;32m    180\u001b[0m     xlm_roberta_xl,\n\u001b[0;32m    181\u001b[0m     xlnet,\n\u001b[0;32m    182\u001b[0m     yolos,\n\u001b[0;32m    183\u001b[0m     yoso,\n\u001b[0;32m    184\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\mt5\\__init__.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     23\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     is_torch_available,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m is_sentencepiece_available():\n\u001b[1;32m---> 33\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mt5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenization_t5\u001b[39;00m \u001b[39mimport\u001b[39;00m T5Tokenizer\n\u001b[0;32m     34\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdummy_sentencepiece_objects\u001b[39;00m \u001b[39mimport\u001b[39;00m T5Tokenizer\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, List, Optional, Tuple\n\u001b[0;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msentencepiece\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mspm\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenization_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedTokenizer\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m     30\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\tokenization_utils.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedDict\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, Union, overload\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtokenization_utils_base\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     ENCODE_KWARGS_DOCSTRING,\n\u001b[0;32m     28\u001b[0m     ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING,\n\u001b[0;32m     29\u001b[0m     INIT_TOKENIZER_DOCSTRING,\n\u001b[0;32m     30\u001b[0m     AddedToken,\n\u001b[0;32m     31\u001b[0m     BatchEncoding,\n\u001b[0;32m     32\u001b[0m     EncodedInput,\n\u001b[0;32m     33\u001b[0m     EncodedInputPair,\n\u001b[0;32m     34\u001b[0m     PreTokenizedInput,\n\u001b[0;32m     35\u001b[0m     PreTokenizedInputPair,\n\u001b[0;32m     36\u001b[0m     PreTrainedTokenizerBase,\n\u001b[0;32m     37\u001b[0m     TextInput,\n\u001b[0;32m     38\u001b[0m     TextInputPair,\n\u001b[0;32m     39\u001b[0m     TruncationStrategy,\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m PaddingStrategy, TensorType, add_end_docstrings, logging\n\u001b[0;32m     44\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:74\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjnp\u001b[39;00m  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mif\u001b[39;00m is_tokenizers_available():\n\u001b[1;32m---> 74\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m \u001b[39mimport\u001b[39;00m AddedToken\n\u001b[0;32m     75\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Encoding \u001b[39mas\u001b[39;00m EncodingFast\n\u001b[0;32m     76\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\tokenizers\\__init__.py:95\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m     CONTIGUOUS \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcontiguous\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtokenizers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m     AddedToken,\n\u001b[0;32m     82\u001b[0m     Encoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m     trainers,\n\u001b[0;32m     94\u001b[0m )\n\u001b[1;32m---> 95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimplementations\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     96\u001b[0m     BertWordPieceTokenizer,\n\u001b[0;32m     97\u001b[0m     ByteLevelBPETokenizer,\n\u001b[0;32m     98\u001b[0m     CharBPETokenizer,\n\u001b[0;32m     99\u001b[0m     SentencePieceBPETokenizer,\n\u001b[0;32m    100\u001b[0m     SentencePieceUnigramTokenizer,\n\u001b[0;32m    101\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\tokenizers\\implementations\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase_tokenizer\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseTokenizer\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbert_wordpiece\u001b[39;00m \u001b[39mimport\u001b[39;00m BertWordPieceTokenizer\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbyte_level_bpe\u001b[39;00m \u001b[39mimport\u001b[39;00m ByteLevelBPETokenizer\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\tokenizers\\implementations\\base_tokenizer.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m \u001b[39mimport\u001b[39;00m AddedToken, EncodeInput, Encoding, InputSequence, Tokenizer\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecoders\u001b[39;00m \u001b[39mimport\u001b[39;00m Decoder\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnormalizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Normalizer\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpre_tokenizers\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTokenizer\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1040\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\") #内部有模型，用于回答问题的\n",
    "\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\n",
    "\"\"\"\n",
    "question_answerer(question=\"What is extractive question answering?\", context=context)\n",
    "\n",
    "#中文版\n",
    "from transformers import AutoModelForQuestionAnswering,AutoTokenizer,pipeline\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('uer/roberta-base-chinese-extractive-qa')\n",
    "tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-chinese-extractive-qa')\n",
    "zh_qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "QA_input = {\n",
    "    'question': \"著名诗歌《假如生活欺骗了你》的作者是\",\n",
    "    'context': \"普希金从那里学习人民的语言，吸取了许多有益的养料，\\\n",
    "        这一切对普希金后来的创作产生了很大的影响。这两年里，普希金创作了不少优秀的作品，如《囚徒》、\\\n",
    "            《致大海》、《致凯恩》和《假如生活欺骗了你》等几十首抒情诗，叙事诗《努林伯爵》，历史剧\\\n",
    "                《鲍里斯·戈都诺夫》，以及《叶甫盖尼·奥涅金》前六章。\"\n",
    "                }\n",
    "zh_qa(QA_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你', '好', '吗', '，', '吃', '饭', '了', '吗', '?']\n",
      "{'input_ids': [[101, 5031, 3428, 3221, 679, 7444, 6206, 102, 0, 0, 0, 0, 0, 0, 0], [101, 2130, 1059, 679, 7444, 6206, 818, 862, 7583, 1912, 3082, 868, 102, 0, 0], [101, 1914, 3340, 3144, 2945, 1469, 1296, 3340, 3144, 2945, 671, 3416, 6822, 6121, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# input_ids: 各字符编号，其中101表开始，102表句子结束[SEP]，0为补齐\n",
    "# attention_mask: 补齐后末尾有0.用此指示哪些是有用信息\n",
    "# token_type_ids: 有时处理问答问题，则输入是两句，用此表示两句，其中第一句全0，第二句全一，若还有第三句则又全0\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\") #https://huggingface.co/有很多模型\n",
    "sen = \"你好吗，吃饭了吗?\"\n",
    "tokens = tokenizer.tokenize(sen)\n",
    "print(tokens)\n",
    "\n",
    "sens = [\"答案是不需要\",\"完全不需要任何额外操作\",\"多条数据和单条数据一样进行调用即可.\"]\n",
    "res = tokenizer(\n",
    "    sens, \n",
    "    padding=\"max_length\", #不足补齐\n",
    "    max_length=15,\n",
    "    truncation=True #超过截断\n",
    "    )\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets\n",
    "来自hugging官网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acronym_identification',\n",
       " 'ade_corpus_v2',\n",
       " 'adversarial_qa',\n",
       " 'aeslc',\n",
       " 'afrikaans_ner_corpus',\n",
       " 'ag_news',\n",
       " 'ai2_arc',\n",
       " 'air_dialogue',\n",
       " 'ajgt_twitter_ar',\n",
       " 'allegro_reviews']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可下载数据集\n",
    "from datasets import list_datasets\n",
    "list_datasets()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration madao33--new-title-chinese-2423910db071caac\n",
      "Found cached dataset csv (C:/Users/zjt/.cache/huggingface/datasets/madao33___csv/madao33--new-title-chinese-2423910db071caac/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31d9d81806f433c9349af1b352ce784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 5850\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 1679\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#下载数据集\n",
    "from datasets import load_dataset\n",
    "dt= load_dataset(\"madao33/new-title-chinese\") #一个数据集\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content'],\n",
       "    num_rows: 5850\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '望海楼美国打“台湾牌”是危险的赌博',\n",
       " 'content': '近期，美国国会众院通过法案，重申美国对台湾的承诺。对此，中国外交部发言人表示，有关法案严重违反一个中国原则和中美三个联合公报规定，粗暴干涉中国内政，中方对此坚决反对并已向美方提出严正交涉。\\n事实上，中国高度关注美国国内打“台湾牌”、挑战一中原则的危险动向。近年来，作为“亲台”势力大本营的美国国会动作不断，先后通过“与台湾交往法”“亚洲再保证倡议法”等一系列“挺台”法案，“2019财年国防授权法案”也多处触及台湾问题。今年3月，美参院亲台议员再抛“台湾保证法”草案。众院议员继而在4月提出众院版的草案并在近期通过。上述法案的核心目标是强化美台关系，并将台作为美“印太战略”的重要伙伴。同时，“亲台”议员还有意制造事端。今年2月，5名共和党参议员致信众议院议长，促其邀请台湾地区领导人在国会上发表讲话。这一动议显然有悖于美国与台湾的非官方关系，其用心是实质性改变美台关系定位。\\n上述动向出现并非偶然。在中美建交40周年之际，两国关系摩擦加剧，所谓“中国威胁论”再次沉渣泛起。美国对华认知出现严重偏差，对华政策中负面因素上升，保守人士甚至成立了“当前中国威胁委员会”。在此背景下，美国将台海关系作为战略抓手，通过打“台湾牌”在双边关系中增加筹码。特朗普就任后，国会对总统外交政策的约束力和塑造力加强。其实国会推动通过涉台法案对行政部门不具约束力，美政府在2018年并未提升美台官员互访级别，美军舰也没有“访问”台湾港口，保持着某种克制。但从美总统签署国会通过的法案可以看出，国会对外交产生了影响。立法也为政府对台政策提供更大空间。\\n然而，美国需要认真衡量打“台湾牌”成本。首先是美国应对危机的代价。美方官员和学者已明确发出警告，美国卷入台湾问题得不偿失。美国学者曾在媒体发文指出，如果台海爆发危机，美国可能需要“援助”台湾，进而导致新的冷战乃至与中国大陆的冲突。但如果美国让台湾自己面对，则有损美国的信誉，影响美盟友对同盟关系的支持。其次是对中美关系的危害。历史证明，中美合则两利、斗则两伤。中美关系是当今世界最重要的双边关系之一，保持中美关系的稳定发展，不仅符合两国和两国人民的根本利益，也是国际社会的普遍期待。美国蓄意挑战台湾问题的底线，加剧中美关系的复杂性和不确定性，损害两国在重要领域合作，损人又害己。\\n美国打“台湾牌”是一场危险的赌博。台湾问题是中国核心利益，中国政府和人民决不会对此坐视不理。中国敦促美方恪守一个中国原则和中美三个联合公报规定，阻止美国会审议推进有关法案，妥善处理涉台问题。美国悬崖勒马，才是明智之举。\\n（作者系中国国际问题研究院国际战略研究所副所长）'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 5265\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 585\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自行分割数据集\n",
    "dt1 = dt[\"train\"]\n",
    "dt1 = dt1.train_test_split(test_size=0.1)\n",
    "dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#选取过滤数据\n",
    "# 选取\n",
    "dt[\"train\"].select([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\zjt\\.cache\\huggingface\\datasets\\madao33___csv\\madao33--new-title-chinese-2423910db071caac\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-abe034542a196555.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content'],\n",
       "    num_rows: 544\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 过滤\n",
    "dt[\"train\"].filter(lambda example: \"中国\" in example[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eab1938edba48929745b0f63a0d2545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5850 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611ed5dbbd534c77b66cda10fa09401e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1679 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Prefix: 望海楼美国打“台湾牌”是危险的赌博'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map\n",
    "def add_prefix(example):\n",
    "    example[\"title\"] = 'Prefix: ' + example[\"title\"]\n",
    "    return example\n",
    "dt1 = dt.map(add_prefix)\n",
    "dt1[\"train\"][0][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1221cc575b64178b41c65db75debb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a904b87d4f404a4c90f0688764985d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5850\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'content', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1679\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实际中一般如下使用\n",
    "from transformers import AutoTokenizer\n",
    "tkzr = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "def preprocess_function(example):\n",
    "    model_inputs = tkzr(example[\"content\"], max_length=512, truncation=True)\n",
    "    labels = tkzr(example[\"title\"], max_length=32, truncation=True)\n",
    "    # label就是title编码的结果\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "dt1 = dt.map(preprocess_function,batched=True) #批处理\n",
    "dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'近期，美国国会众院通过法案，重申美国对台湾的承诺。对此，中国外交部发言人表示，有关法案严重违反一个中国原则和中美三个联合公报规定，粗暴干涉中国内政，中方对此坚决反对并已向美方提出严正交涉。\\n事实上，中国高度关注美国国内打“台湾牌”、挑战一中原则的危险动向。近年来，作为“亲台”势力大本营的美国国会动作不断，先后通过“与台湾交往法”“亚洲再保证倡议法”等一系列“挺台”法案，“2019财年国防授权法案”也多处触及台湾问题。今年3月，美参院亲台议员再抛“台湾保证法”草案。众院议员继而在4月提出众院版的草案并在近期通过。上述法案的核心目标是强化美台关系，并将台作为美“印太战略”的重要伙伴。同时，“亲台”议员还有意制造事端。今年2月，5名共和党参议员致信众议院议长，促其邀请台湾地区领导人在国会上发表讲话。这一动议显然有悖于美国与台湾的非官方关系，其用心是实质性改变美台关系定位。\\n上述动向出现并非偶然。在中美建交40周年之际，两国关系摩擦加剧，所谓“中国威胁论”再次沉渣泛起。美国对华认知出现严重偏差，对华政策中负面因素上升，保守人士甚至成立了“当前中国威胁委员会”。在此背景下，美国将台海关系作为战略抓手，通过打“台湾牌”在双边关系中增加筹码。特朗普就任后，国会对总统外交政策的约束力和塑造力加强。其实国会推动通过涉台法案对行政部门不具约束力，美政府在2018年并未提升美台官员互访级别，美军舰也没有“访问”台湾港口，保持着某种克制。但从美总统签署国会通过的法案可以看出，国会对外交产生了影响。立法也为政府对台政策提供更大空间。\\n然而，美国需要认真衡量打“台湾牌”成本。首先是美国应对危机的代价。美方官员和学者已明确发出警告，美国卷入台湾问题得不偿失。美国学者曾在媒体发文指出，如果台海爆发危机，美国可能需要“援助”台湾，进而导致新的冷战乃至与中国大陆的冲突。但如果美国让台湾自己面对，则有损美国的信誉，影响美盟友对同盟关系的支持。其次是对中美关系的危害。历史证明，中美合则两利、斗则两伤。中美关系是当今世界最重要的双边关系之一，保持中美关系的稳定发展，不仅符合两国和两国人民的根本利益，也是国际社会的普遍期待。美国蓄意挑战台湾问题的底线，加剧中美关系的复杂性和不确定性，损害两国在重要领域合作，损人又害己。\\n美国打“台湾牌”是一场危险的赌博。台湾问题是中国核心利益，中国政府和人民决不会对此坐视不理。中国敦促美方恪守一个中国原则和中美三个联合公报规定，阻止美国会审议推进有关法案，妥善处理涉台问题。美国悬崖勒马，才是明智之举。\\n（作者系中国国际问题研究院国际战略研究所副所长）'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1['train'][0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 6818, 3309, 8024, 5401]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1['train'][0]['input_ids'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1['train'][0]['token_type_ids'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1['train'][0]['attention_mask'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 3307, 3862, 3517, 5401]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1['train'][0]['labels'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d768252d973b4a6f85f2261d10b11eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c54144c6d943ab8ee3de5e17cca634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1679 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\datasets\\dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 5850\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 1679\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存处理完的数据\n",
    "from datasets import load_from_disk\n",
    "dt.save_to_disk(\"./news_data\")\n",
    "dt = load_from_disk(\"./news_data\")\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cc9a47e40b59d786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/zjt/.cache/huggingface/datasets/csv/default-cc9a47e40b59d786/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f7aa8981f94ccda746d1e2466f0c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84864a888ac24d26badb305260850150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ba704cbdc54b37b8c5bc4e11fdfc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/zjt/.cache/huggingface/datasets/csv/default-cc9a47e40b59d786/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3876888866904d37852d01fa9e111619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'discourse_id', 'discourse_start', 'discourse_end', 'discourse_text', 'discourse_type', 'discourse_type_num', 'predictionstring'],\n",
       "        num_rows: 144293\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 本地数据集加载\n",
    "dt = load_dataset(\"csv\", data_files='E:\\\\DATA\\\\feedback-prize-2021\\\\train.csv')\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '423A1CA112E2',\n",
       " 'discourse_id': 1622627660524.0,\n",
       " 'discourse_start': 8.0,\n",
       " 'discourse_end': 229.0,\n",
       " 'discourse_text': 'Modern humans today are always on their phone. They are always on their phone more than 5 hours a day no stop .All they do is text back and forward and just have group Chats on social media. They even do it while driving.',\n",
       " 'discourse_type': 'Lead',\n",
       " 'discourse_type_num': 'Lead 1',\n",
       " 'predictionstring': '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非格式数据处理？？？？？？？？？？？？？？？？？？？？？？？？？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#下载\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"bert-base-chinese\",\n",
    "    #cache_dir=\"./\" #模型保存路径\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4893,  0.0480, -0.1033,  ...,  0.6812, -0.5084, -0.3696],\n",
       "         [-0.3242,  0.2772, -0.9865,  ..., -0.3170, -0.5676, -0.6787],\n",
       "         [ 1.4281, -1.4412, -1.1542,  ...,  0.6870, -0.3307, -0.4802],\n",
       "         ...,\n",
       "         [ 0.3103,  0.2867, -0.0655,  ...,  0.8095,  0.4969, -0.2483],\n",
       "         [ 0.1014,  0.0843, -0.3567,  ...,  0.6308,  0.0326, -0.1445],\n",
       "         [-0.0165,  0.0576, -0.1530,  ...,  0.4274, -0.3527, -0.5036]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.9998,  1.0000,  0.9990,  0.9671,  0.9570,  0.9432, -0.3311, -0.9890,\n",
       "          0.9939, -0.9989,  1.0000,  0.9998,  0.4891, -0.9078,  0.9999, -0.9998,\n",
       "         -0.2507,  0.9932,  0.9929, -0.0138,  0.9995, -1.0000, -0.8328, -0.6283,\n",
       "          0.1023,  0.9946,  0.9475, -0.9810, -0.9999,  0.9991,  0.9751,  0.9997,\n",
       "          0.9946, -1.0000, -0.9996,  0.6571, -0.2026,  0.9981, -0.4456, -0.8336,\n",
       "         -0.9469, -0.8985, -0.8123, -0.9984, -0.9937,  0.8664, -1.0000, -1.0000,\n",
       "          0.7500,  0.9999, -0.8859, -1.0000,  0.9449, -0.8030, -0.5920,  0.9973,\n",
       "         -0.9999,  0.9741,  1.0000,  0.9592,  0.9997, -0.9876, -0.5223, -0.9999,\n",
       "          1.0000, -0.9998, -0.9873, -0.0514,  1.0000,  1.0000, -0.9800,  0.9941,\n",
       "          1.0000,  0.1028,  0.9840,  0.9996, -0.9990,  0.6320, -1.0000, -0.1577,\n",
       "          1.0000,  0.9990, -0.9418,  0.8916, -0.9883, -1.0000, -0.9971,  1.0000,\n",
       "          0.0778,  0.9989,  0.9995, -0.9979, -1.0000,  0.9984, -0.9991, -0.9997,\n",
       "         -0.6088,  0.9988,  0.6510, -0.9452, -0.6086,  0.9483, -0.9992, -0.9980,\n",
       "          0.9806,  0.9980,  0.6282, -0.9988,  1.0000,  0.2755, -1.0000, -0.9317,\n",
       "         -1.0000, -0.9897, -0.9942,  0.9999, -0.1308,  0.1667,  0.9998, -0.9987,\n",
       "          0.8708, -0.9997, -0.1494,  0.4746,  0.9990,  0.9999,  0.9993, -0.9982,\n",
       "          0.9996,  1.0000,  0.9885,  0.9903, -0.9987,  0.9944,  0.3316, -0.9864,\n",
       "          0.2665, -0.9235,  1.0000,  0.9832,  0.9880, -0.9969,  0.9999, -0.9993,\n",
       "          1.0000, -1.0000,  0.9996, -1.0000, -0.9995,  0.9977,  0.9879,  1.0000,\n",
       "         -0.7710,  1.0000, -0.9977, -1.0000,  0.9940,  0.6044,  0.9974, -0.9999,\n",
       "          0.8613,  0.4166, -0.4448, -0.7926, -1.0000,  1.0000, -0.9054,  1.0000,\n",
       "          0.9989, -0.9687, -0.9794, -0.9990,  0.9132, -0.9998, -0.9279,  0.9937,\n",
       "          0.2282,  0.9989, -0.7021, -0.9248,  0.9873, -0.0348, -1.0000,  0.9980,\n",
       "         -0.6436,  0.8579,  0.5148,  0.5017,  0.9498,  0.7398, -0.8984,  1.0000,\n",
       "          0.3103,  0.9920,  0.9990,  0.4297, -0.8565, -0.9456, -1.0000, -0.8384,\n",
       "          1.0000, -0.7537, -0.9997,  0.7080, -1.0000,  0.9106, -0.0032,  0.4031,\n",
       "         -0.9993, -0.9999,  0.9999, -0.9821, -0.9992,  0.7008, -0.5639, -0.2576,\n",
       "         -0.9998,  0.7380,  0.9621, -0.5300,  0.9049, -0.8513, -0.9994,  0.9983,\n",
       "         -0.9787,  0.8883,  0.5319,  1.0000,  0.9779, -0.8023, -0.8372,  1.0000,\n",
       "          0.1668, -1.0000,  0.9291, -0.9977,  0.1617,  0.9999, -0.9978,  0.6160,\n",
       "          1.0000,  0.9939,  1.0000, -0.0346, -0.9995, -0.9982,  1.0000,  0.9938,\n",
       "          0.9999, -0.9998, -0.9966,  0.4648, -0.9846, -1.0000, -0.9967, -0.5779,\n",
       "          0.9957,  1.0000, -0.4585, -0.9998, -0.8233, -0.9994,  1.0000, -0.9903,\n",
       "          1.0000,  0.9855, -0.9995, -0.9930, -0.0697, -0.7715, -0.9997,  0.7957,\n",
       "         -1.0000, -0.9964, -0.9999,  0.9054, -0.9996, -1.0000,  0.9837,  0.9999,\n",
       "          0.9413, -1.0000,  0.9999,  0.9986, -0.4400, -0.9999,  0.9630, -1.0000,\n",
       "          1.0000, -0.9983,  0.9285, -0.8299, -0.9927,  0.9416,  0.9997,  0.9998,\n",
       "         -0.9980, -0.0119, -0.9850, -0.9922, -0.5638,  0.8188, -0.0474,  0.8873,\n",
       "         -0.9703, -0.4423,  0.7762, -0.9628, -1.0000,  0.9062,  1.0000, -0.9299,\n",
       "          1.0000,  0.8089,  1.0000,  0.8114, -0.9989,  0.9992,  0.8788, -0.9238,\n",
       "         -0.9932, -0.9877,  0.9252,  0.6873, -0.2186, -0.9999,  1.0000,  0.9925,\n",
       "          0.9882,  0.6606,  0.0428,  0.0542,  0.9652, -0.9986,  0.9977, -0.9997,\n",
       "         -0.9826,  0.9998,  1.0000,  0.9996,  0.7297, -0.9481,  0.9866, -0.9988,\n",
       "          0.9994, -0.9998,  0.9986, -0.9700,  0.6322, -0.8479, -0.9978,  1.0000,\n",
       "          0.9923, -0.8584,  0.9998, -0.9053,  0.9773,  0.9907,  0.9958,  0.9832,\n",
       "          0.9687,  1.0000, -0.9983, -0.9950, -0.9471, -0.9932, -0.9992, -1.0000,\n",
       "          0.1383, -0.9989, -0.9908, -0.2207,  0.8576,  0.9865, -0.8341,  0.6704,\n",
       "          0.3915,  0.5625, -0.8157,  0.6454,  0.9749, -0.9958, -0.9937, -1.0000,\n",
       "         -0.9992,  0.7567,  0.9999, -0.9999,  0.9993, -0.9999, -0.9974,  0.9998,\n",
       "         -0.8730, -0.8943,  0.9998, -1.0000,  0.9843,  1.0000,  1.0000,  0.9993,\n",
       "          0.9999, -0.9397, -0.9998, -0.9996, -1.0000, -1.0000, -1.0000,  0.9093,\n",
       "         -0.2561, -1.0000, -0.8312,  0.9890,  1.0000,  0.9763, -0.9995,  0.2109,\n",
       "         -0.9996, -0.9936,  0.9992, -0.9766, -0.9999,  0.9889, -0.3865,  1.0000,\n",
       "         -0.6658,  0.8709,  0.7250,  0.9134,  0.9869, -1.0000,  0.7714,  1.0000,\n",
       "          0.7804, -1.0000, -0.7269, -0.9380, -1.0000, -0.3418,  0.8705,  0.9999,\n",
       "         -1.0000, -0.8958, -0.9977,  0.9047,  0.9953,  0.9999,  0.9998,  0.9301,\n",
       "          0.8164,  0.9979, -0.1239,  0.9999,  0.4748, -0.9992,  0.9992, -0.7648,\n",
       "          0.4372, -0.9999,  0.9987,  0.9156,  1.0000,  0.9884, -0.2510, -0.9693,\n",
       "         -0.9465,  0.9925,  1.0000, -0.9986, -0.9855, -0.9997, -1.0000, -0.9981,\n",
       "         -0.8792, -0.4149, -0.9934, -0.9991,  0.6267,  0.9474,  1.0000,  1.0000,\n",
       "          0.9996, -0.9035, -0.9456,  0.9930,  0.1251,  0.9891, -0.9843, -1.0000,\n",
       "         -0.9984, -0.9998,  0.9999, -0.0648, -0.7437, -0.9304,  0.2382,  0.8682,\n",
       "         -0.9999, -0.7781, -0.9968,  0.8905,  1.0000, -0.9983,  0.9997, -0.9992,\n",
       "          0.8846,  0.6891,  0.8187,  0.9995, -0.1932,  0.3184, -0.7378,  0.8028,\n",
       "          0.8751,  0.9978, -0.9179,  0.7640,  0.9996, -0.8985,  0.9999,  0.4608,\n",
       "          0.8327,  0.9182,  1.0000,  0.4390,  0.9989,  0.9963,  1.0000,  0.9999,\n",
       "         -0.9953,  0.4207,  0.3868, -0.9539, -0.6277,  0.7886,  1.0000,  0.5087,\n",
       "         -0.9788, -0.9999,  0.9914,  0.9997,  1.0000,  0.5314,  0.9985,  0.4909,\n",
       "          0.7666,  0.9007,  0.8938,  0.5903,  0.5780,  0.9964,  0.9996, -0.9999,\n",
       "         -1.0000, -1.0000,  1.0000,  0.9999, -0.9551, -1.0000,  0.9997, -0.8485,\n",
       "          0.9485,  0.9953,  0.1383, -0.4583,  0.7934, -0.9998,  0.0438,  0.9736,\n",
       "          0.8260,  0.6528,  0.9998, -0.9999, -0.0588,  1.0000, -0.3853,  1.0000,\n",
       "          0.2064, -0.9975,  0.9992, -0.9950, -1.0000, -0.8079,  1.0000,  0.9997,\n",
       "         -0.2915, -0.7028,  0.9999, -0.9998,  0.9999, -0.9999,  0.7320, -0.9996,\n",
       "          0.9999, -0.9871, -0.9988, -0.9328,  0.9728,  0.8029, -0.9259,  1.0000,\n",
       "         -0.1275, -0.8398,  0.4345, -0.9656, -0.9971, -0.9887,  0.4897, -1.0000,\n",
       "          0.8242,  0.8222, -0.9278, -0.9876, -1.0000,  1.0000, -0.8206, -0.9880,\n",
       "          0.9999, -0.9849, -1.0000,  0.9300, -0.9989,  0.0406,  0.9891,  0.8704,\n",
       "          0.1355, -1.0000,  0.5408,  1.0000, -0.9989, -0.8145, -0.8150, -0.9712,\n",
       "          0.9889,  0.9984,  0.7006, -0.8014,  0.9357,  0.9969,  0.9146,  0.3066,\n",
       "          0.5914, -0.9993, -0.9997, -0.9799, -0.9986, -0.9999, -1.0000,  1.0000,\n",
       "          0.9999,  1.0000, -0.5310, -0.8730,  0.9501,  0.9934, -0.9996, -0.0382,\n",
       "          0.5533,  0.9623, -0.6595, -0.9995, -0.3326, -1.0000, -0.6415,  0.3089,\n",
       "         -0.8952,  0.6907,  1.0000,  1.0000, -0.9998, -0.9990, -0.9983, -0.9994,\n",
       "          1.0000,  0.9990,  0.9998, -0.9059, -0.8397,  0.9978, -0.7802,  0.4919,\n",
       "         -0.9992, -0.9955, -1.0000,  0.9064, -0.9973, -0.9999,  0.9982,  1.0000,\n",
       "          0.7983, -1.0000, -0.9160,  1.0000,  0.9990,  1.0000,  0.4275,  0.9999,\n",
       "         -0.9941,  0.9957, -0.9990,  1.0000, -1.0000,  1.0000,  0.9999,  0.9993,\n",
       "          0.9982, -0.9929,  0.8084, -0.9424, -0.5462,  0.9672, -0.5580, -0.9951,\n",
       "         -0.0851,  0.9927, -0.8584,  1.0000,  0.7830,  0.4812,  0.6529,  0.5518,\n",
       "          0.9984, -0.9850, -0.9998,  0.9950,  0.9966,  0.9854,  1.0000,  0.9903,\n",
       "          1.0000, -0.9831, -0.9991,  0.9917, -0.8757,  0.3639, -1.0000,  1.0000,\n",
       "          1.0000, -0.9999, -0.9568,  0.3484,  0.6916,  1.0000,  0.9994,  0.9989,\n",
       "          0.8156,  0.5523,  0.9995, -0.9994,  0.9849, -0.9100, -0.9895,  1.0000,\n",
       "         -0.9575,  0.9996, -0.9856,  0.9999, -0.9996,  0.9028,  0.9941,  0.9577,\n",
       "         -0.9948,  1.0000,  0.7443, -0.9983, -0.9982, -0.9972, -0.9985,  0.9254]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model(**tokenizer(\"弱小的我也有大梦想\", return_tensors=\"pt\")) #pt:pytorch,tf:tenserflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        'bert-base-cased', \n",
    "        num_labels=3\n",
    ") #文本分类型，各种模型就是for后面的内容不同"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lvwerra/test',\n",
       " 'precision',\n",
       " 'code_eval',\n",
       " 'roc_auc',\n",
       " 'cuad',\n",
       " 'xnli',\n",
       " 'rouge',\n",
       " 'pearsonr',\n",
       " 'mse',\n",
       " 'super_glue',\n",
       " 'comet',\n",
       " 'cer',\n",
       " 'sacrebleu',\n",
       " 'mahalanobis',\n",
       " 'wer',\n",
       " 'competition_math',\n",
       " 'f1',\n",
       " 'recall',\n",
       " 'coval',\n",
       " 'mauve',\n",
       " 'xtreme_s',\n",
       " 'bleurt',\n",
       " 'ter',\n",
       " 'accuracy',\n",
       " 'exact_match',\n",
       " 'indic_glue',\n",
       " 'spearmanr',\n",
       " 'mae',\n",
       " 'squad',\n",
       " 'chrf',\n",
       " 'glue',\n",
       " 'perplexity',\n",
       " 'mean_iou',\n",
       " 'squad_v2',\n",
       " 'meteor',\n",
       " 'bleu',\n",
       " 'wiki_split',\n",
       " 'sari',\n",
       " 'frugalscore',\n",
       " 'google_bleu',\n",
       " 'bertscore',\n",
       " 'matthews_correlation',\n",
       " 'seqeval',\n",
       " 'trec_eval',\n",
       " 'rl_reliability',\n",
       " 'jordyvl/ece',\n",
       " 'angelina-wang/directional_bias_amplification',\n",
       " 'cpllab/syntaxgym',\n",
       " 'lvwerra/bary_score',\n",
       " 'kaggle/amex',\n",
       " 'kaggle/ai4code',\n",
       " 'hack/test_metric',\n",
       " 'yzha/ctc_eval',\n",
       " 'codeparrot/apps_metric',\n",
       " 'mfumanelli/geometric_mean',\n",
       " 'daiyizheng/valid',\n",
       " 'poseval',\n",
       " 'erntkn/dice_coefficient',\n",
       " 'mgfrantz/roc_auc_macro',\n",
       " 'Vlasta/pr_auc',\n",
       " 'gorkaartola/metric_for_tp_fp_samples',\n",
       " 'idsedykh/metric',\n",
       " 'idsedykh/codebleu2',\n",
       " 'idsedykh/codebleu',\n",
       " 'idsedykh/megaglue',\n",
       " 'kasmith/woodscore',\n",
       " 'cakiki/ndcg',\n",
       " 'brier_score',\n",
       " 'Vertaix/vendiscore',\n",
       " 'GMFTBY/dailydialogevaluate',\n",
       " 'GMFTBY/dailydialog_evaluate',\n",
       " 'jzm-mailchimp/joshs_second_test_metric',\n",
       " 'ola13/precision_at_k',\n",
       " 'yulong-me/yl_metric',\n",
       " 'abidlabs/mean_iou',\n",
       " 'abidlabs/mean_iou2',\n",
       " 'KevinSpaghetti/accuracyk',\n",
       " 'Felipehonorato/my_metric',\n",
       " 'NimaBoscarino/weat',\n",
       " 'ronaldahmed/nwentfaithfulness',\n",
       " 'Viona/infolm',\n",
       " 'kyokote/my_metric2',\n",
       " 'kashif/mape',\n",
       " 'Ochiroo/rouge_mn',\n",
       " 'giulio98/code_eval_outputs',\n",
       " 'leslyarun/fbeta_score',\n",
       " 'giulio98/codebleu',\n",
       " 'anz2/iliauniiccocrevaluation',\n",
       " 'zbeloki/m2',\n",
       " 'xu1998hz/sescore',\n",
       " 'mase',\n",
       " 'mape',\n",
       " 'smape',\n",
       " 'dvitel/codebleu',\n",
       " 'NCSOFT/harim_plus',\n",
       " 'JP-SystemsX/nDCG',\n",
       " 'sportlosos/sescore',\n",
       " 'Drunper/metrica_tesi',\n",
       " 'jpxkqx/peak_signal_to_noise_ratio',\n",
       " 'jpxkqx/signal_to_reconstrution_error',\n",
       " 'hpi-dhc/FairEval',\n",
       " 'nist_mt',\n",
       " 'lvwerra/accuracy_score',\n",
       " 'character',\n",
       " 'charcut_mt',\n",
       " 'fengyuli2002/clip_score',\n",
       " 'ybelkada/cocoevaluate']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "evaluate.list_evaluation_modules(\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa5c48cc3434bda9c9c0689be6ec1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mType:\u001b[0m        Accuracy\n",
      "\u001b[1;31mString form:\u001b[0m\n",
      "EvaluationModule(name: \"accuracy\", module_type: \"metric\", features: {'predictions': Value(dtype=' <...> .4])\n",
      "           >>> print(results)\n",
      "           {'accuracy': 0.8778625954198473}\n",
      "           \"\"\", stored examples: 0)\n",
      "\u001b[1;31mLength:\u001b[0m      0\n",
      "\u001b[1;31mFile:\u001b[0m        c:\\users\\zjt\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--accuracy\\f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14\\accuracy.py\n",
      "\u001b[1;31mDocstring:\u001b[0m  \n",
      "Accuracy is the proportion of correct predictions among the total number of cases processed. It can be computed with:\n",
      "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
      " Where:\n",
      "TP: True positive\n",
      "TN: True negative\n",
      "FP: False positive\n",
      "FN: False negative\n",
      "\n",
      "Args:\n",
      "    predictions (`list` of `int`): Predicted labels.\n",
      "    references (`list` of `int`): Ground truth labels.\n",
      "    normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.\n",
      "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n",
      "\n",
      "Returns:\n",
      "    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.\n",
      "\n",
      "Examples:\n",
      "\n",
      "    Example 1-A simple example\n",
      "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
      "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])\n",
      "        >>> print(results)\n",
      "        {'accuracy': 0.5}\n",
      "\n",
      "    Example 2-The same as Example 1, except with `normalize` set to `False`.\n",
      "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
      "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)\n",
      "        >>> print(results)\n",
      "        {'accuracy': 3.0}\n",
      "\n",
      "    Example 3-The same as Example 1, except with `sample_weight` set.\n",
      "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
      "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])\n",
      "        >>> print(results)\n",
      "        {'accuracy': 0.8778625954198473}\n"
     ]
    }
   ],
   "source": [
    "?accuracy_metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "# 创建TrainingArguments\n",
    "args = TrainingArguments(\n",
    "        'outputs', \n",
    "        learning_rate=8e-5, \n",
    "        warmup_ratio=0.1, \n",
    "        lr_scheduler_type='cosine', \n",
    "        fp16=True,\n",
    "        evaluation_strategy=\"epoch\", \n",
    "        per_device_train_batch_size=64, \n",
    "        per_device_eval_batch_size=128,\n",
    "        num_train_epochs=10, \n",
    "        weight_decay=0.01, \n",
    "        report_to='none'\n",
    "        )\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        'bert-base-cased', \n",
    "        num_labels=3\n",
    ")\n",
    "# 创建Trainer\n",
    "trainer = Trainer(\n",
    "        model, \n",
    "        args, \n",
    "        train_dataset=[], \n",
    "        eval_dataset=[],\n",
    "        tokenizer=AutoTokenizer.from_pretrained(\"bert-base-chinese\"), \n",
    "        compute_metrics=lambda prey,y:nn.BCEWithLogitsLoss()(prey,y)\n",
    "        )\n",
    "# 模型训练\n",
    "trainer.train()\n",
    "# 模型评估\n",
    "trainer.evaluate()\n",
    "# 模型预测\n",
    "trainer.predict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train'] ['sample_submission.csv', 'test.csv', 'train.csv', '来源.txt']\n"
     ]
    }
   ],
   "source": [
    "#阅览数据\n",
    "data_dir = \"E:/DATA/feedback-prize-effectiveness/\"\n",
    "for root,dirs,files in os.walk(data_dir):\n",
    "    print(dirs,files)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  \n",
       "0                Adequate  \n",
       "1                Adequate  \n",
       "2                Adequate  \n",
       "3                Adequate  \n",
       "4                Adequate  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_dir,\"train.csv\"))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discourse_type             [Lead, Position, Claim, Evidence, Counterclaim...\n",
       "discourse_effectiveness                   [Adequate, Ineffective, Effective]\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['discourse_type','discourse_effectiveness']].apply(pd.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4191\n",
      "4191\n"
     ]
    }
   ],
   "source": [
    "print(len(pd.unique(train_df['essay_id'])))\n",
    "for _,_,files in os.walk(os.path.join(data_dir,\"train\")):\n",
    "    print(len(files))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>a great chance to learn something new</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>can be very helpful and beneficial.</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  a261b6e14276  D72CB1C11673   \n",
       "1  5a88900e7dc1  D72CB1C11673   \n",
       "2  9790d835736b  D72CB1C11673   \n",
       "3  75ce6d68b67b  D72CB1C11673   \n",
       "4  93578d946723  D72CB1C11673   \n",
       "\n",
       "                                      discourse_text discourse_type  \n",
       "0  Making choices in life can be very difficult. ...           Lead  \n",
       "1  Seeking multiple opinions can help a person ma...       Position  \n",
       "2                     it can decrease stress levels           Claim  \n",
       "3             a great chance to learn something new           Claim  \n",
       "4               can be very helpful and beneficial.           Claim  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_dir,\"test.csv\"))\n",
    "test_df.head()\n",
    "\n",
    "#可知文本类型已知，所以考虑如何将文本类型作为输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [Lead]\n",
       "1                [Position]\n",
       "2                   [Claim]\n",
       "3                   [Claim]\n",
       "4                   [Claim]\n",
       "5                [Evidence]\n",
       "6                [Evidence]\n",
       "7                   [Claim]\n",
       "8                [Evidence]\n",
       "9    [Concluding Statement]\n",
       "Name: discourse_type, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['discourse_type'].apply(pd.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(pd.unique(test_df['essay_id'])))\n",
    "for _,_,files in os.walk(os.path.join(data_dir,\"test\")):\n",
    "    print(len(files))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>ef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  type  ef\n",
       "0  007ACE74B050  Hi, i'm Isaac, i'm going to be writing about h...     1   1\n",
       "1  007ACE74B050  On my perspective, I think that the face is a ...     2   1\n",
       "2  007ACE74B050  I think that the face is a natural landform be...     3   1\n",
       "3  007ACE74B050  If life was on Mars, we would know by now. The...     4   1\n",
       "4  007ACE74B050  People thought that the face was formed by ali...     5   1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#列的处理\n",
    "data_dir = \"E:/DATA/feedback-prize-effectiveness/\"\n",
    "train_df = pd.read_csv(os.path.join(data_dir,\"train.csv\"))\n",
    "\n",
    "needed_col = ['essay_id','discourse_text','discourse_type','discourse_effectiveness']\n",
    "train_df = train_df[needed_col]\n",
    "train_df.columns=['id','text','type','ef']\n",
    "\n",
    "#typ = {'Lead':1,'Position':2, 'Claim':3, 'Evidence':4, 'Counterclaim':5, 'Rebuttal':6, 'Concluding Statement':7}\n",
    "#eff = {'Adequate':1, 'Ineffective':2, 'Effective':3}\n",
    "#train_df['type'] = train_df['type'].apply(lambda x:typ[x])\n",
    "#train_df['ef'] = train_df['ef'].apply(lambda x:eff[x])\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "train_df.to_csv(os.path.join(data_dir,\"proc_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_dir,\"proc_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext' has no attribute 'legacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\project\\python\\feedback-prize-effectiveness\\exp.ipynb Cell 61\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#词处理\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#Y114sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m torchtext\u001b[39m.\u001b[39;49mlegacy\u001b[39m.\u001b[39mdata\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#Y114sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text_field \u001b[39m=\u001b[39m torchtext\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mField(sequential\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, tokenize\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mspacy\u001b[39m\u001b[39m'\u001b[39m,lower\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m#会自行处理停用词和符号\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/project/python/feedback-prize-effectiveness/exp.ipynb#Y114sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m label_field \u001b[39m=\u001b[39m torchtext\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mField(sequential\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,use_vocab\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m#是单独的类别，而不是文本，原数据可以是数字\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchtext' has no attribute 'legacy'"
     ]
    }
   ],
   "source": [
    "#词处理\n",
    "text_field = torchtext.data.Field(sequential=True, tokenize='spacy',lower=True,batch_first=True) #会自行处理停用词和符号\n",
    "label_field = torchtext.data.Field(sequential=False,use_vocab=False)#是单独的类别，而不是文本，原数据可以是数字\n",
    "\n",
    "fields = [('id',None),('text',text_field),('type',label_field),('ef',label_field)]\n",
    "train_dataset = torchtext.data.TabularDataset(os.path.join(data_dir,\"proc_train.csv\"),'csv',fields)\n",
    "\n",
    "text_field.build_vocab(train_dataset,vector='glove.6B.100d')\n",
    "label_field.build_vocab(train_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "data_dir = \"E:/DATA/feedback-prize-effectiveness/\"\n",
    "\n",
    "assist_dir = \"./assist/\"\n",
    "if(not os.path.exists(assist_dir)):\n",
    "    os.mkdir(assist_dir)\n",
    "models_dir = \"./models_dir/\"\n",
    "if(not os.path.exists(models_dir)):\n",
    "    os.mkdir(models_dir)\n",
    "exp_name = \"exp1\"\n",
    "exp_dir = os.path.join(models_dir,exp_name)\n",
    "if(not os.path.exists(exp_dir)):\n",
    "    os.mkdir(exp_dir)\n",
    "\n",
    "word_count = 60 #不能让大部分数据空值太多\n",
    "max_word_count = 100 #超过这个值考虑取首尾\n",
    "wordvector_dir = \"E:/DATA/glove.6B/\"\n",
    "\n",
    "stop_words_file = \"E:/DATA/english_stop_words.txt\"\n",
    "\n",
    "train_batch_size=64\n",
    "valid_batch_size=128\n",
    "test_batch_size=128\n",
    "epochs=15\n",
    "\n",
    "seed=101\n",
    "def set_seed():\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed()\n",
    "\n",
    "exp_name = \"exp1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 未优化版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只运行一次，产生处理过的csv\n",
    "\n",
    "#列重命名\n",
    "train_df1 = pd.read_csv(os.path.join(data_dir,\"train.csv\"))\n",
    "needed_col = ['essay_id','discourse_text','discourse_type','discourse_effectiveness']\n",
    "train_df1 = train_df1[needed_col]\n",
    "train_df1.columns=['id','text','type','ef']\n",
    "\n",
    "#type加到text首\n",
    "train_df1['text'] = train_df1[['text','type']].apply(lambda x:x[1]+\".\"+x[0] if x[1]==\"Concluding Statement\" else \"Conclusion.\"+x[0],axis=1)\n",
    "\n",
    "#type数字化\n",
    "typ = {'Claim':0,\"Concluding Statement\":1,\"Counterclaim\":2,\"Evidence\":3,\"Lead\":4,\"Position\":5,\"Rebuttal\":6}\n",
    "train_df1['type'] = train_df1['type'].apply(lambda x:typ[x])\n",
    "#ef数字化\n",
    "eff = {'Adequate':0, 'Ineffective':1, 'Effective':2}\n",
    "train_df1['ef'] = train_df1['ef'].apply(lambda x:eff[x])\n",
    "\n",
    "#统计单词个数供划分用\n",
    "train_df1['wordcount'] = train_df1['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    "    )\n",
    "\n",
    "#分训练集验证集\n",
    "train_df1['fold']=[-1]*len(train_df1)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for i, (train_i,valid_i) in enumerate(skf.split(train_df1,train_df1['type'])):\n",
    "    train_df1.loc[valid_i,'fold'] = i+1\n",
    "train_df = train_df1[train_df1['fold']!=1]\n",
    "train_df = train_df.drop(labels=['fold'],axis=1)\n",
    "valid_df = train_df1[train_df1['fold']==1]\n",
    "valid_df = valid_df.drop(labels=['fold'],axis=1)\n",
    "\n",
    "#保存\n",
    "train_df.to_csv(os.path.join(assist_dir,\"train.csv\"),index=None)\n",
    "valid_df.to_csv(os.path.join(assist_dir,\"valid.csv\"),index=None)\n",
    "\n",
    "\n",
    "#测试集，也需要对text进行处理，同时获取wordcount\n",
    "test_df = pd.read_csv(os.path.join(data_dir,\"test.csv\"))\n",
    "needed_col = ['essay_id','discourse_text','discourse_type']\n",
    "test_df = test_df[needed_col]\n",
    "test_df.columns=['id','text','type']\n",
    "\n",
    "test_df['text'] = test_df[['text','type']].apply(lambda x:x[1]+\".\"+x[0] if x[1]==\"Concluding Statement\" else \"Conclusion.\"+x[0],axis=1)\n",
    "#type数字化\n",
    "typ = {'Claim':0,\"Concluding Statement\":1,\"Counterclaim\":2,\"Evidence\":3,\"Lead\":4,\"Position\":5,\"Rebuttal\":6}\n",
    "test_df['type'] = test_df['type'].apply(lambda x:typ[x])\n",
    "\n",
    "#为了下面生成train、valid、test的代码可以写到一起，对test也设计ef列\n",
    "test_df['ef'] = [0]*len(test_df)\n",
    "\n",
    "test_df['wordcount'] = test_df['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    "    )\n",
    "\n",
    "test_df.to_csv(os.path.join(assist_dir,\"test.csv\"),index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(321)\n",
    "plt.hist(x = list(train_df1['wordcount']),bins=80)\n",
    "\n",
    "plt.subplot(322)\n",
    "plt.hist(x = list(train_df1[train_df1['wordcount']<=200]['wordcount']),bins=20)\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.bar(x = [0,1], height = [len(train_df1[train_df1['wordcount']<=word_count]),len(train_df1[train_df1['wordcount']>word_count])])\n",
    "\n",
    "plt.subplot(324)\n",
    "plt.bar(x = [0,1], height = [len(train_df1[train_df1['wordcount']<=max_word_count]),len(train_df1[train_df1['wordcount']>max_word_count])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36765.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.841480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46.842673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>837.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wordcount\n",
       "count  36765.000000\n",
       "mean      45.841480\n",
       "std       46.842673\n",
       "min        2.000000\n",
       "25%       17.000000\n",
       "50%       29.000000\n",
       "75%       58.000000\n",
       "max      837.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1[['wordcount']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化版\n",
    "\n",
    "数据好像没什么变化？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只有训练集进行太长截断取首尾\n",
    "\n",
    "#列重命名\n",
    "train_df1 = pd.read_csv(os.path.join(data_dir,\"train.csv\"))\n",
    "needed_col = ['essay_id','discourse_text','discourse_type','discourse_effectiveness']\n",
    "train_df1 = train_df1[needed_col]\n",
    "train_df1.columns=['id','text','type','ef']\n",
    "\n",
    "#type加到text首\n",
    "train_df1['text'] = train_df1[['text','type']].apply(lambda x:x[1]+\".\"+x[0] if x[1]==\"Concluding Statement\" else \"Conclusion.\"+x[0],axis=1)\n",
    "\n",
    "#type数字化\n",
    "typ = {'Claim':0,\"Concluding Statement\":1,\"Counterclaim\":2,\"Evidence\":3,\"Lead\":4,\"Position\":5,\"Rebuttal\":6}\n",
    "train_df1['type'] = train_df1['type'].apply(lambda x:typ[x])\n",
    "#ef数字化\n",
    "eff = {'Adequate':0, 'Ineffective':1, 'Effective':2}\n",
    "train_df1['ef'] = train_df1['ef'].apply(lambda x:eff[x])\n",
    "\n",
    "#验证集的text保存原样\n",
    "train_df1['wordcount'] = train_df1['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    "    )\n",
    "\n",
    "#划分\n",
    "train_df1['fold']=[-1]*len(train_df1)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for i, (train_i,valid_i) in enumerate(skf.split(train_df1,train_df1['type'])):\n",
    "    train_df1.loc[valid_i,'fold'] = i+1\n",
    "train_df = train_df1[train_df1['fold']!=1]\n",
    "train_df = train_df.drop(labels=['fold'],axis=1)\n",
    "valid_df = train_df1[train_df1['fold']==1]\n",
    "valid_df = valid_df.drop(labels=['fold'],axis=1)\n",
    "\n",
    "valid_df.to_csv(os.path.join(assist_dir,\"valid1.csv\"),index=None)\n",
    "\n",
    "#对训练集再单独处理\n",
    "def f(x):\n",
    "    #句子太长优先取首尾\n",
    "    text = x['text']\n",
    "    sp_word = r\"[\\n|\\s|,|?|!|.]\"\n",
    "    sp_sentence = r\"[\\n|?|!|.]\" #不以,划分\n",
    "\n",
    "    L = len(list(filter(None, re.split(sp_word, text))))\n",
    "    if L>max_word_count:\n",
    "        sentences = list(filter(None, re.split(sp_sentence, text)))\n",
    "\n",
    "        if len(sentences) == 1:\n",
    "            return text\n",
    "\n",
    "        res = sentences[0]+\".\"+sentences[1]+\".\"+sentences[-1]+\".\"\n",
    "\n",
    "        i=2\n",
    "        while len(list(filter(None, re.split(sp_word, res))))<word_count:\n",
    "            if i==len(sentences)-1:\n",
    "                break\n",
    "            res+=sentences[i]+\".\"\n",
    "\n",
    "            i+=1\n",
    "        return res\n",
    "        \n",
    "    else:\n",
    "        return text\n",
    "\n",
    "train_df['text'] = train_df[['text']].apply(f,axis=1)\n",
    "train_df['wordcount'] = train_df['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    "    )\n",
    "train_df.to_csv(os.path.join(assist_dir,\"train1.csv\"),index=None)\n",
    "\n",
    "#测试集也不用截断\n",
    "test_df = pd.read_csv(os.path.join(data_dir,\"test.csv\"))\n",
    "needed_col = ['essay_id','discourse_text','discourse_type']\n",
    "test_df = test_df[needed_col]\n",
    "test_df.columns=['id','text','type']\n",
    "\n",
    "test_df['text'] = test_df[['text','type']].apply(lambda x:x[1]+\".\"+x[0] if x[1]==\"Concluding Statement\" else \"Conclusion.\"+x[0],axis=1)\n",
    "\n",
    "#type数字化\n",
    "typ = {'Claim':0,\"Concluding Statement\":1,\"Counterclaim\":2,\"Evidence\":3,\"Lead\":4,\"Position\":5,\"Rebuttal\":6}\n",
    "test_df['type'] = test_df['type'].apply(lambda x:typ[x])\n",
    "\n",
    "#为了下面生成train、valid、test的代码可以写到一起，对test也设计ef列\n",
    "test_df['ef'] = [0]*len(test_df)\n",
    "\n",
    "test_df['wordcount'] = test_df['text'].apply(\n",
    "    lambda x: len(list(filter(None, re.split(r\"[\\n|\\s|,|!|.|?]\", x))))\n",
    "    )\n",
    "\n",
    "test_df.to_csv(os.path.join(assist_dir,\"test1.csv\"),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36765.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.841480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46.842673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>837.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wordcount\n",
       "count  36765.000000\n",
       "mean      45.841480\n",
       "std       46.842673\n",
       "min        2.000000\n",
       "25%       17.000000\n",
       "50%       29.000000\n",
       "75%       58.000000\n",
       "max      837.000000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1[['wordcount']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(321)\n",
    "plt.hist(x = list(train_df1['wordcount']),bins=80)\n",
    "\n",
    "plt.subplot(322)\n",
    "plt.hist(x = list(train_df1[train_df1['wordcount']<=200]['wordcount']),bins=20)\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.bar(x = [0,1], height = [len(train_df1[train_df1['wordcount']<=word_count]),len(train_df1[train_df1['wordcount']>word_count])])\n",
    "\n",
    "plt.subplot(324)\n",
    "plt.bar(x = [0,1], height = [len(train_df1[train_df1['wordcount']<=max_word_count]),len(train_df1[train_df1['wordcount']>max_word_count])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460 58 1\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(assist_dir,\"train.csv\"))\n",
    "valid_df = pd.read_csv(os.path.join(assist_dir,\"valid.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(assist_dir,\"test.csv\"))\n",
    "\n",
    "#词处理\n",
    "with open(stop_words_file,'r') as f:\n",
    "    stop_words = [i.split(\"\\n\")[0] for i in f.readlines()]\n",
    "text_field = data.Field(\n",
    "    sequential=True, tokenize='spacy',tokenizer_language = \"en_core_web_sm\", \n",
    "    lower=True,\n",
    "    batch_first=True,\n",
    "    fix_length=word_count,\n",
    "    stop_words=stop_words\n",
    "    )\n",
    "label_field = data.Field(sequential=False, use_vocab=False) #已经是数字，所以use_vocab=False\n",
    "\n",
    "#就是这里，需要它们的fields都为这个\n",
    "fields = [('id',None),('text',text_field),('type',label_field),\\\n",
    "          ('ef',label_field),('wordcount',label_field)]\n",
    "\n",
    "train_ds, valid_ds, test_ds = data.TabularDataset.splits(\n",
    "    path = assist_dir, format = 'csv',\n",
    "    train='train.csv', validation='valid.csv', test='test.csv',\n",
    "    fields=fields,\n",
    "    skip_header = True\n",
    "    )\n",
    "\n",
    "text_field.build_vocab(\n",
    "    train_ds,valid_ds,test_ds,\n",
    "    vectors='glove.6B.50d',\n",
    "    vectors_cache=wordvector_dir\n",
    "    )\n",
    "label_field.build_vocab(train_ds,valid_ds,test_ds)\n",
    "\n",
    "'''\n",
    "for w,i in text_field.vocab.stoi.items():#词和相应index\n",
    "    print(w,i)\n",
    "print(text_field.vocab.vectors.shape)#[29278, 100]\n",
    "'''\n",
    "\n",
    "train_iter, valid_iter, test_iter = torchtext.legacy.data.BucketIterator.splits(#长度相似的会放同一批\n",
    "    (train_ds, valid_ds, test_ds),\n",
    "    batch_sizes = (train_batch_size, valid_batch_size, test_batch_size),#一样的话就是batch_size\n",
    "    sort=True,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: int(x.wordcount),\n",
    "    device = device\n",
    "    )\n",
    "\n",
    "print(len(train_iter),len(valid_iter),len(test_iter))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model参数\n",
    "\n",
    "#embedding层\n",
    "embedding_shape = text_field.vocab.vectors.shape\n",
    "embedding_weight = text_field.vocab.vectors\n",
    "\n",
    "#lstm层\n",
    "hidden_size = 2\n",
    "num_layers = 1 #不太清楚设置成其他值怎么弄，下面的代码主要针对为1情况\n",
    "bidirectional = False #是否双向lstm，双向的forward可能要变，初步考虑如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(*embedding_shape)\n",
    "        self.embedding.weight.data.copy_(embedding_weight)#不能直接用=\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=text_field.vocab.vectors.shape[1],\n",
    "            batch_first=True,\n",
    "\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional = bidirectional\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.Linear(hidden_size,3),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def __initHC__(self, batch_size):\n",
    "        self.H = torch.zeros([num_layers,batch_size,hidden_size])\n",
    "        self.C = torch.zeros([num_layers,batch_size,hidden_size])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.embedding(x)\n",
    "\n",
    "        #self.__initHC__(batch_size = x.shape[0])\n",
    "        #x, (outH,outC) = self.lstm(x,(self.H,self.C))\n",
    "        x, (outH,outC) = self.lstm(x)\n",
    "\n",
    "        \"\"\"\n",
    "        if bidirectional:#不一定是这样\n",
    "            out = self.classifier(x[:,[-1],:] + x[:,[0],:])\n",
    "        else:\n",
    "            out = self.classifier(x[:,[-1],:])\n",
    "        \"\"\"\n",
    "        if bidirectional:#不一定是这样\n",
    "            out = self.classifier(outH[0] + outH[0])\n",
    "        else:\n",
    "            out = self.classifier(outH[0])\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(model.embedding.parameters()).clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<CloneBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042],\n",
       "        [0.3839, 0.3119, 0.3042]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "model(list(train_iter)[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss等 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "#loss_func(pred_y,y)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.002)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=len(train_iter)*epochs+10, \n",
    "    eta_min=1e-6\n",
    "    )#整个训练过程完成max->min"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    \"\"\"基本设置\"\"\"\n",
    "    def __init__(self):\n",
    "        self.__pre_proc()\n",
    "\n",
    "\n",
    "    def __pre_proc(self):\n",
    "        model.to(device)\n",
    "        \n",
    "        self.__init_loss()\n",
    "        \n",
    "    def __init_loss(self):\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "    \n",
    "    \n",
    "    def get_loss(self, kind):\n",
    "        if kind == 'train':\n",
    "            return self.train_loss\n",
    "        elif kind == 'valid':\n",
    "            return self.valid_loss\n",
    "        else:\n",
    "            raise ValueError(\"kind值错误\")\n",
    "            \n",
    "    \n",
    "    def __save_model(self, epoch):\n",
    "        path = exp_dir + f\"/epoch_{epoch}_params.pkl\"\n",
    "        model_params = model.state_dict()\n",
    "        torch.save(model_params, path)\n",
    "\n",
    "    \n",
    "    def set_model(self, epoch):\n",
    "        \"\"\"\n",
    "        从文件读出参数\n",
    "\n",
    "        Args:\n",
    "            epoch: 第几轮的参数\n",
    "        \"\"\"\n",
    "        path = exp_dir + f\"/epoch_{epoch}_params.pkl\"\n",
    "        model_params = torch.load(path)\n",
    "        model.load_state_dict(model_params)\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"训练相关\"\"\"\n",
    "    def train(self):\n",
    "        self.__init_loss()\n",
    "        for epoch in range(epochs):\n",
    "            self.train_one_epoch(epoch)\n",
    "            self.valid_one_epoch(epoch)\n",
    "\n",
    "            #self.__smw_proc(epoch)\n",
    "        \n",
    "        \n",
    "    def train_one_epoch(self, epoch):\n",
    "        model.train()\n",
    "        \n",
    "        scaler = amp.GradScaler()\n",
    "        \n",
    "        epoch_loss = 0 #统计本epoch的总loss，最后求平均loss\n",
    "        data_size = 0\n",
    "        pbar = tqdm(enumerate(train_iter), total=len(train_iter), desc=f'epoch_{epoch} train')\n",
    "        for i, batch in pbar:      \n",
    "            x = batch.text\n",
    "            y = batch.ef\n",
    "            \n",
    "            with amp.autocast():\n",
    "                predy = model(x)\n",
    "                batch_loss = loss_func(predy.squeeze(1), y)\n",
    "            scaler.scale(batch_loss).backward()\n",
    "            \n",
    "            if i%1==0:\n",
    "                scaler.step(optimizer)#1个batch更新一次参数\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step() #同时更新lr\n",
    "                \n",
    "            epoch_loss += float(batch_loss)*train_batch_size\n",
    "            data_size += train_batch_size\n",
    "            \n",
    "            mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            pbar.set_postfix(\n",
    "                peoch_avg_loss=f'{epoch_loss/data_size:0.4f}',\n",
    "                lr=f'{current_lr:0.4f}',\n",
    "                gpu_mem=f'{mem:0.2f} GB'\n",
    "            )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    " \n",
    "        self.train_loss.append(epoch_loss/data_size)\n",
    "        self.__save_model(epoch)\n",
    "        \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valid_one_epoch(self, epoch):\n",
    "        model.eval()\n",
    "        \n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "        epoch_loss = 0 #统计本epoch的总loss，最后求平均loss\n",
    "        data_size = 0\n",
    "        pbar = tqdm(enumerate(valid_iter), total=len(valid_iter), desc=f'epoch_{epoch} valid')\n",
    "        for i, batch in pbar:\n",
    "            x = batch.text\n",
    "            y = batch.ef\n",
    "\n",
    "            with amp.autocast():\n",
    "                predy = model(x)\n",
    "                batch_loss = loss_func(predy.squeeze(1), y)\n",
    "                \n",
    "            epoch_loss += float(batch_loss)*valid_batch_size\n",
    "            data_size += valid_batch_size\n",
    "            \n",
    "            mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "            pbar.set_postfix(\n",
    "                peoch_avg_loss=f'{epoch_loss/data_size:0.4f}',\n",
    "                gpu_mem=f'{mem:0.2f} GB'\n",
    "            )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        self.valid_loss.append(epoch_loss/data_size)\n",
    "        \n",
    "        \n",
    "    \"\"\"测试集\"\"\"\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        返回预测结果和loss\n",
    "        \"\"\"\n",
    "        \n",
    "        temp = [] #存储结果\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "        cur_loss = 0\n",
    "        data_size = 0\n",
    "        pbar = tqdm(enumerate(test_iter), total=len(test_iter), desc='test')\n",
    "        for i, batch in pbar:\n",
    "            x = batch.text\n",
    "            y = batch.ef\n",
    "\n",
    "            with amp.autocast():\n",
    "                predy = model(x)\n",
    "                temp.append((predy.detach().cpu().numpy(),y.detach().cpu().numpy()))\n",
    "                batch_loss = loss_func(predy.squeeze(1), y)\n",
    "                \n",
    "            cur_loss += float(batch_loss)*test_batch_size\n",
    "            data_size += test_batch_size\n",
    "            \n",
    "            mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "            pbar.set_postfix(\n",
    "                loss=f'{cur_loss/data_size:0.4f}',\n",
    "                gpu_mem=f'{mem:0.2f} GB'\n",
    "            )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        res = []\n",
    "        for predy,y in temp:\n",
    "            for i in range(predy.shape[0]):\n",
    "                res.append((list(predy[i]),list(y[i])))\n",
    "                \n",
    "        return cur_loss/data_size, res\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    \"\"\"可视化结果\"\"\"\n",
    "    def __smw_proc(self,epoch):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "        with SummaryWriter(exp_name) as smw:\n",
    "            smw.add_scalars(\n",
    "                main_tag='datas/loss',\n",
    "                tag_scalar_dict={\n",
    "                    \"train_loss\":self.train_loss[f\"epoch_{epoch}\"],\n",
    "                    \"valid_loss\":self.valid_loss[f\"epoch_{epoch}\"],\n",
    "                    },\n",
    "                global_step=epoch\n",
    "            )\n",
    "            smw.add_scalar(\n",
    "                tag='datas/lr',\n",
    "                scalar_value=optimizer.param_groups[0]['lr'],\n",
    "                global_step=epoch\n",
    "            )\n",
    "\n",
    "            imgs,masks,pred_masks = self.__get_show_result('train',2)\n",
    "            for i in range(imgs.shape[0]):\n",
    "                dis_imgs = np.stack([i for i in imgs[i]]+[i for i in masks[i]]+[i for i in pred_masks[i]],axis=0)\n",
    "                dis_imgs = dis_imgs[:,np.newaxis]\n",
    "                self.smw.add_images(\n",
    "                    tag=f\"epoch_{epoch}/train/{i}\",\n",
    "                    img_tensor=dis_imgs\n",
    "                )\n",
    "            imgs,masks,pred_masks = self.__get_show_result('valid',2)\n",
    "            for i in range(imgs.shape[0]):\n",
    "                dis_imgs = np.stack([i for i in imgs[i]]+[i for i in masks[i]]+[i for i in pred_masks[i]],axis=0)\n",
    "                dis_imgs = dis_imgs[:,np.newaxis]\n",
    "                smw.add_images(\n",
    "                    tag=f\"epoch_{epoch}/valid/{i}\",\n",
    "                    img_tensor=dis_imgs\n",
    "                )\n",
    "\n",
    "runner = Runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2034, 0.2028, 0.5938]], grad_fn=<SelectBackward>) tensor([0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 2, 2, 1, 0, 0, 2, 2, 2, 2, 1, 0,\n",
      "        1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "for batch in train_iter:\n",
    "    out = model(batch.text.to(device))\n",
    "    y = batch.ef\n",
    "    break\n",
    "print(out[0],y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
